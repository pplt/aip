\documentclass[11pt]{amsart}
\input{preamble.tex}

\begin{document}

\title[Arithmetic programming and Frobenius powers]{Arithmetic integer programming and Frobenius powers of monomial ideals
}
\author{Daniel J.\ Hern\'andez}
\author{Pedro Teixeira}
\author{Emily E. Witt}
\maketitle


\newcommand{\denom}{\ell} %We should stick to the same notation for the denominator of a minimal coordinate.  Sometimes D is used, but I would prefer a lowercase letter.  Lowercase "d" makes sense, but we use that for the dimension of the ambient polynomial ring.

\emily[inline]{
TO DO LIST:
\begin{enumerate}
   %\item[$\CheckedBox$]
 \item[$\Box$] Write essential statements/proofs.
 \item[$\Box$] Decide on name of paper.
 \item[$\Box$] Decide on name for minimal coordinate.
 \pedro[inline]{
    Do we have a consensus for ``special points''? If so, I'll go ahead and make the change. 
 }
 \item[$\Box$] Make sprout notation.
 \daniel[inline]{I saw that someone used $\operatorname{sp}$ for sprouts.  One possible issue is that we may want to reserve this for ``special points", which we had already proposed as a replacement for ``minimal corodinate".  Another things to keep in mind is that sprouting depends on $p \in \ZZ$, so this should also be taken into account.}
 \pedro[inline]{Good point. How about simply ``$\operatorname{sprout}(A,\vv{u},p)$''? ``$\operatorname{sprout}_p(A,\vv{u})$''? ``$p\text{-sprout}(A,\vv{u})$"? I think the first is probably the most obvious and consistent with other notation in the paper.
 }
 \item[$\Box$] Put in examples.
 \item[$\Box$] Decide on how to define $\widehat{\witt}$.  (Sprouting graph?)
 \pedro[inline]{I'm trying $\graph$ for the notation, for ``sprouting graph''. Let's see if we like it.}  \daniel[inline]{Can someone explain why the graphs now start at the $0$-th level? }
 \pedro[inline]{
    I did that, because I think that's how we were thinking of them in our conversations in Lawrence.
    For example, we were saying that $\bigcup_{e\ge 1}\graph^e(A,p)$ is finite, because we were thinking of the initial level consisting of all (possibly infinitely many) small pairs as level 0.
    I have a slight preference for starting at 0, but wouldn't mind changing it back, if you prefer. 
 }
 \item[$\Box$] Fill in/rewrite preliminaries.
 \item[$\Box$] Reorganize and motivate the $\Pi$ and $\Theta$, and their connection, in Sections 5 and 6.
 \item[$\Box$] ``Fractal linear program;'' solve $P$ in ``Sierpinski gasket''
 \pedro[inline]{
    I started an outline as a separate section, at the end.
    However, some of this could be introduced along with the AIPs.
 }
 \item[$\Box$] Direct proof that $\delta$/$\Delta$ are independent of $\vv{s}$.
 \item[$\Box$] Minimize and/or ``algebrafy'' statements.
 \item[$\Box$] Background section on Frobenius powers, $\mu$, $\nu$, etc.
 \item[$\Box$] Derive some easy corollaries for very general hypersurfaces.
 \item[$\Box$] Generalize the definition of $\IP$ so that $\IP(A, \vv{u}q)$ becomes $\IP(A, \vv{u}, q)$?  
\end{enumerate}
}

\newpage

\section{Preliminaries}

\comment[inline]{The only things in this section that are ``new" are \Cref{bounded polytope: L} (which is kind of obvious) and \Cref{vertex: L} (a technical result we will need later)}


\subsection{Euclidean spaces, convexity and polyhedra} 
\ \comment[inline]{This subsection has *no* overlap with other paper}


 \alert[inline]{Add discussion of inner products, positivity, inequalities of vectors, polyhedra, polytopes, Minkokwski sum, convex hull, cone, standard basis elements, relative interior commutes with Minkowski sum}


\begin{lemma}  
   \label{bounded polytope: L}
   Let $\vv{a}$ and $\vv{c}$ be points in $\RR^m$, and suppose that $\vv{a}$ has positive coordinates.
   If $\alpha$ is any real number, then the polyhedron consisting of all points $\vv{b} \in \RR^m$ such that  $\vv{b} < \vv{c} \text{ and } \iprod{\vv{a}}{\vv{b}} \geq \alpha$ is bounded.
\end{lemma}

\begin{proof}
   Suppose that the polyhedron $P$ described above is nonempty.
   To show that $P$ is bounded, it suffices to show that its recession cone is trivial.
   In other words, fix $\vv{b} \in P$ and suppose that $\vv{d} \in \RR^m$ is such that $\vv{b} + \lambda \vv{d} \in P$ for all $\lambda > 0$.
   To show that $P$ is bounded, we must show that $\vv{d} = \vv{0}$.
   However,  the constraint $\vv{b} + \lambda \vv{d} < \vv{c}$ for all $\lambda>0$ implies that $\vv{d} \leq \vv{0}$, and combining this with the constraint $\iprod{\vv{a}}{\vv{b} + \lambda \vv{d}} \geq \alpha$ for all $\lambda > 0$ and the positivity of $\vv{a}$ then implies that no coordinate of $\vv{d}$ can be negative.
\end{proof}

\pedro[inline]{
   Here is an alternate, more explicit proof:

   It suffices to show that the given set is bounded from below.
   For each $\vv{b}$ in that set and each $i$, we have $\vv{b}\le \vv{c} + (b_i - c_i)\canvec_i$.
   As $\vv{a}$ has positive coordinates, $\alpha\le \iprod{\vv{a}}{\vv{b}}\le \iprod{\vv{a}}{\vv{c} + (b_i -c_i)\canvec_i} = \iprod{\vv{a}}{\vv{c}} + a_i(b_i - c_i)$, so $b_i\ge (\alpha + a_ic_i - \iprod{\vv{a}}{\vv{c}})/a_i$.
}


We conclude this subsection with a useful technical result.  Though variations of this lemma are well-known, we include a simple proof, for lack of an appropriate reference.


\begin{lemma}  
\label{vertex: L}
Let $M$ be an $m \times n$ matrix and let $\vv{b} \in \RR^m$ be a point contained in the cone generated by the columns of $M$.  If $\Q$ is the polyhedron in $\RR^n$  consisting of all points $\vv{t}$ with $\vv{t} \geq \vv{0}$ and $M \vv{t} = \vv{b}$, then a point $\vv{t}^{\ast} \in \Q$ is a vertex of $\Q$ if and only if the columns of $M$ corresponding to the nonzero coordinates of $\vv{t}^{\ast}$ are linearly independent.  %In particular, $\Q$ contains a vertex.
\end{lemma}

\begin{proof}
   The fact that $\vv{b}$ lies in the cone generated by the columns of $M$ implies that $\Q$ is nonempty.
   Fix a point $\vv{t}^{\ast} \in \Q$.
   Before proceeding, recall that $\vv{t}^{\ast}$ is a vertex of $\Q$ if and only if the only expression of $\vv{t}^{\ast}$ as a convex combination of points $\vv{r} \in \Q$ and $\vv{s} \in \Q$ is when $\vv{r}=\vv{s}=\vv{t}^{\ast}$.

   First, assume that the columns of $M$ corresponding to the nonzero coordinates of $\vv{t}^{\ast}$ are linearly independent, and suppose that $\vv{t}^{\ast} = \lambda \vv{r} + \mu \vv{s}$ is a convex combination of points $\vv{r}, \vv{s} \in \Q$.
   Since $\vv{r},\vv{s}\ge \vv{0}$, the $i$-th coordinate of $\vv{r}$ and of $\vv{s}$ are zero whenever the $i$-th coordinate of $\vv{t}^{\ast}$ is zero.
   On the other hand, the fact that $\vv{r}$ and $\vv{s}$ lie in $\Q$ also implies that
   \[ M \vv{t}^{\ast} = \vv{b} = M \vv{r} = M \vv{s}, \]
   and the assumption that the columns of $M$ corresponding to the nonzero coordinates of $\vv{t}^{\ast}$ are linearly independent then implies that $\vv{r}=\vv{s}=\vv{t}^{\ast}$.

Next, suppose that the columns of $M$ corresponding to the nonzero coordinates of $\vv{t}^{\ast}$ are linearly dependent.   In this case, we may fix a nonzero point $\vv{k} \in \RR^n$ with the property that $M \vv{k} = \vv{0}$, and such that the $i$-th coordinate of $\vv{k}$ is zero whenever the $i$-th coordinate of $\vv{t}^{\ast}$ is zero.  We claim that if $\varepsilon > 0$ is sufficiently small, then the points $\vv{t}^{\ast} \pm \varepsilon \vv{k}$ must lie in $\Q$.   As $\vv{t}^{\ast}$ is a convex combination of these points, it will then follow that $\vv{t}^{\ast}$ is not a vertex of $\Q$.  Towards the claim, note that $M(\vv{t}^{\ast} \pm \varepsilon \vv{k}) = M \vv{t}^{\ast} = \vv{b}$ for every $\varepsilon > 0$.  On the other hand, the condition relating the coordinates of $\vv{t}^{\ast}$ and $\vv{k}$ guarantees that $\vv{t}^{\ast} \pm \varepsilon \vv{k}$ is nonnegative for all $0 < \varepsilon \ll 1$.  
%
%To conclude the proof, it remains to show that $\Q$ contains a vertex.  However, Carath\'eodory's Theorem for cones tells us that the cone generated by the columns of $M$ is the union of the cones generated by the sublists of these columns that are linearly independent.  This observation and the fact that $\Q$ is nonempty imply that this polyhedron must contain a vertex.
\end{proof}



\subsection{Monomial matrices}  A \emph{monomial matrix} is a matrix over $\ZZ$ with nonnegative, nonzero rows and columns.   If $A$ is a $d \times n$ monomial matrix, then we call $\ZZ^n$ the \emph{domain lattice}, and $\ZZ^d$ the \emph{range lattice}, of $A$.

\pedro[inline]{The terminology introduced below is not being used.}
A  monomial matrix $B$ is a \emph{successor} of $A$ if $B$ can be obtained from $A$ by omitting some (possibly empty) subset of its rows.   The most relevant example of a successor is the collapse construction considered later in \Cref{newton-polyhedra: S}.  A successor $B$ of $A$ is  \emph{proper} if $B \neq A$.



\subsection{Linear programming}  

Let $\mathbb{D}$ be either $\RR$ or $\ZZ$.
A \emph{linear program} $\Pi$ in $\mathbb{D}^n$ is an optimization problem in which one seeks to maximize a fixed linear \emph{objective function} $\RR^n \to \RR$ on a subset of $\mathbb{D}^n$ defined by a fixed system of linear inequalities.
We refer to this subset as the \emph{feasible set} of $\Pi$, and denote it $\feas \Pi$, and we refer to the inequalities defining it as the \emph{constraints} of $\Pi$.  
In the case that $\mathbb{D} = \ZZ$, we will refer to $\Pi$ as an \emph{integer linear program}, or simply \emph{integer program}, for short.  

If $\mathbb{D} = \RR$, then the feasible set  will be a polyhedron in $\RR^n$, and if $\mathbb{D} = \ZZ$, then the feasible set will be the lattice points in a polyhedron in $\RR^n$.  

In this article, we will only consider linear programs $\Pi$ in which the objective function restricted to the feasible set attains a maximum (\eg this occurs whenever the constraints of $\Pi$ define a polytope).
In this case, a feasible point is \emph{optimal} if it maximizes the objective function, and the optimal value obtained by this function is called the \emph{value} of the $\Pi$.
We use $\opt \Pi$ to denote optimal set of $\Pi$, and $\val \Pi$ to denote the value of $\Pi$. 

There are clearly multiple reasonable notions of equality for integer programs.
In this article,  we say that two integer programs are \emph{equal} if their objective functions and defining constraints are identical, and \emph{equivalent} if their objective functions are identical and their feasible sets agree. 




\newpage

\section{Frobenius powers and critical exponents}

In this section, we recall the definition and basic properties of generalized Frobenius powers, as introduced in \cite{hernandez+etal.frobenius_powers}.
Let $R$ be a regular domain of characteristic $p > 0$, and let $\ideala$ be an ideal of $R$.
If $q$ is a power of $p$, then $\ideala^{[q]}$ denotes the standard $q$-th Frobenius power of $\ideala$, that is, the ideal generated by the $q$-th powers of the elements of $\ideala$.
Given a nonnegative integer $k$, with base $p$ expansion $k = k_0 + k_1 p + \cdots + k_r p^r$, the $k$-th Frobenius power of $\ideala$ is the ideal
\[\ideala^{[k]} \coloneqq \ideala^{k_0}\big(\ideala^{k_1}\big)^{[p]}\cdots \big(\ideala^{k_r}\big)^{[p^r]}.\]
If $\ideala = \ideal{f_1,\ldots,f_n}$, then $\ideala^{[k]}$ is the ideal generated by the products $f_1^{m_1}\cdots f_n^{m_n}$, where $(m_1,\ldots,m_n)$ ranges over all $n$-tuples of nonnegative integers with $\binom{k}{m_1,\ldots,m_n}\not\equiv 0\bmod{p}$.

Frobenius powers are extended to allow nonnegative real exponents, through the use of the $[1/p^e]$-th powers of \cite{blickle+mustata+smith.discr_rat_FPTs}.
Explicitly, for a nonnegative rational exponent of the form $k/p^e$, we define
\[\ideala^{[k/p^e]} \coloneqq \big(\ideala^{[k]}\big)^{[1/p^e]},\]
and for an arbitrary positive real number $t$, we define $\ideala^{[t]}$ by taking approximations of $t$ from above by such rational numbers, in a way analogous to the definition of test ideals in \loccit
\pedro{Make this more explicit?}

Like test ideals and multiplier ideals, the Frobenius powers $\ideala^{[t]}$ form a nested, nonincreasing chain, that is right-constant for positive $t$, \ie $\ideala^{[t+\epsilon]} = \ideala^{[t]}$, for $0<\epsilon \ll 1$.
The positive exponents where $\ideala^{[t]}$ ``jumps'' (that is, $\ideala^{[t-\epsilon]}\ne \ideala^{[t]}$, for all $0<\epsilon \le t$) are called the \emph{critical exponents} of $\ideala$.

\todo[inline]{
   TBC\ldots
   
   Define $\crit(\ideala,\idealb)$, and realize it a a limit of $\mu$s.

   Specialize to monomial ideals.
}


\daniel[inline]{
Suppose $\ideala$ is a monomial ideal.  Then all of its Frobenius powers are also monomial ideals, and \[ x^{\vv{v}} \in \ideala^{[\lambda]} \iff \ideala^{[\lambda]} \not \subseteq \diag(\vv{v}+\vv{1}) \iff \crit(\ideala, \vv{v}+\vv{1}) > \lambda.\]  The first $\iff$ above is Proposition 2.5 from our examples paper.  Therefore, 
\[ \ideala^{[\lambda]} = \langle x^{\vv{v}} : \crit(\ideala, \vv{v}+\vv{1}) > \lambda \rangle.\]  This also tells us that every critical value of $\ideala$ is of the form $\crit(\ideala, \vv{u})$ with $\vv{u} > \vv{0}$. Whatever we include in this section should be enough to at least justify this observation.  When we look for corollaries, our ability to compute $\crit(\ideala, \vv{u})$ with $\vv{u} > \vv{1}$ will show that the ideals $\ideala^{[\lambda]}$ also vary ``uniformly'' with respect to the class of $p$ modulo some denominator $\denom$, in a way that we can make precise.
}

\section{Newton polyhedra}
\label{newton-polyhedra: S}

\comment[inline]{This section needs to be paraphrased, to avoid overlap with other paper}
\daniel[inline]{One thing we can do is change the presentation so that it is more informal.  We can include some general ideas, to make it intuitive, but can refer to the other paper for technical details that are obvious, but perhaps annoying to check.}

\subsection{Faces of Newton polyhedra} The \emph{Newton polyhedron} associated to a monomial matrix $A$ with $d$ rows is the polyhedron in $\RR^d$ given by 
\[ \N = \conv( \col(A) ) + \cone( \vv{e}_1, \ldots, \vv{e}_d) \] where $\col(A)$ is the set of columns of $A$.  

Recall that a proper  subset $\O$ of $\N$ is a \emph{face} of $\N$  if there exists $\vv{a} \in \RR^d$ and $\beta \in \RR$ are such that $\iprod{\vv{a}}{\vv{c}} \geq \beta$ for all $\vv{c} \in \N$, with equality if and only if $\vv{c} \in \O$.  We say that  such a point $\vv{a}$ \emph{defines} $\O$ in $\N$.    In this article, we will be concerned with faces $\O$ that do not lie in any coordinate subspace of $\RR^d$.  We call such a face \emph{standard}, and when considering points that define such a face, we will always assume that we have rescaled so that $\beta = 1$. 

The following lemma is well-known to experts, but we include the short proof to keep the article self-contained.
% Below, we review the basic properties of faces of Newton polyhedra.  Though many of these results are well-known to experts, we include the proofs to keep this article self-contained.

\begin{lemma} 
\label{face: L}
If $\vv{a} \in \RR^d$ defines $\O$ in $\N$, then $\vv{a}$ is nonnegative, and the $i$-th coordinate of $\vv{a}$ is zero if and only if $\vv{c} + \lambda \vv{e}_i \in \O$  for every $\vv{c} \in \O$ and $\lambda > 0$.  In particular, the supporting indices of $\vv{a}$ depend only on $\O$, and $\O$ is bounded if and only if $\vv{a}$ is positive. 
\end{lemma}

\begin{proof}  If $\vv{c} \in \O$, then adding to $\vv{c}$ any nonnegative point in $\RR^d$ produces a point in $\N$.  In particular, $\iprod{\vv{a}}{\vv{c}} = \beta$ and $\iprod{\vv{a}}{\vv{c} + \lambda \vv{e}_i} \geq \beta$ for every standard basis vector $\vv{e}_i$ in $\RR^d$ and $\lambda > 0$.  This observation implies that $\vv{a} \geq \vv{0}$, and that $\vv{c} + \lambda \vv{e}_i \in \O$ for every $\lambda > 0$ if and only if $\iprod{\vv{a}}{\vv{e}_i} = 0$.  

Similar logic will show that if $\rb(\O) \coloneqq  \{ \vv{e}_i \in \RR^d : \iprod{\vv{a}}{\vv{e}_i} = 0\}$, then 
\begin{equation}
\label{face: e}
\O =  \conv( \col(A) \cap \O ) + \cone(\rb(\O))
\end{equation}
where we agree that the $\cone(\emptyset) = \vv{0}$.  We see from this that $\O$ is bounded if and only if $\rb(\O)$ is empty, which is equivalent to the third assertion.  
\end{proof}

\begin{definition}
   If $\vv{a} \in \RR^d$ defines $\O$, then the \emph{recession basis} of $\O$ is the set $\rb(\O)$ of all standard basis vectors $\vv{e}_i$ in $\RR^d$ such that the $i$-th coordinate of $\vv{a}$ is zero, and the \emph{recession subspace} of $\O$ is the subspace $\rs(\O)$ of $\RR^d$ spanned by $\rb(\O)$.  
   As noted above, these definitions depend only on $\O$, but not on the choice of $\vv{a}$.
\end{definition}

\pedro[inline]{Why don't we just define recession subspaces instead?
   I'll give it a try, and let's see if it works.
}

Our choice of terminology is motivated by the following observation.

\begin{remark}  Recall that the \emph{recession cone} of a polyhedron $\mathcal{Q}$ in $\RR^d$ is the set of all directions $\vv{d} \in \RR^d$ in which $\mathcal{Q}$ recedes, that is, $\vv{c} + \lambda \vv{d} \in \mathcal{Q}$ for every $\vv{c} \in \mathcal{Q}$ and $\lambda > 0$.  It is a well-known fact from convex geometry that  \eqref{face: e} implies that the cone generated by $\rb(\O)$ is the recession cone of $\O$.
\end{remark}

\subsection{Collapses} 

\begin{definition}  
\label{collapse: D}
 Suppose that $\O$ is a proper face of the Newton polyhedron $\N$ in $\RR^d$ associated to a monomial matrix $A$ with $d$ rows.  

\begin{enumerate}
\item The set $\rb(\O)^{\perp}$ is the complement of $\rb(\O)$ in $\{ \vv{e}_1, \ldots, \vv{e}_d \}$, and $\rs(\O)^\perp$ is the subspace of $\RR^d$ spanned by $\rb(\O)^\perp$, that is, the orthogonal complement of $\rs(\O)$ in $\RR^d$.
\item The \emph{collapse} of a subset $X$ of $\RR^d$ along $\O$ is the image of $X$ under the canonical linear projection $\RR^d \longrightarrow \rs(\O)^{\perp}$.
\item The \emph{collapse} of $A$ along $\O$ is the matrix obtained from $A$ by collapsing each of its columns along $\O$.  That is, the collapse of $A$ along $\O$ is the matrix corresponding to the linear transformation  
%
\[ \RR^n \stackrel{A}{\xrightarrow{\hspace*{6mm}}} \RR^d \longrightarrow \rs(\O)^{\perp}.\]  
%
\end{enumerate}
\end{definition}     

\begin{remark}  The assumption that $\O \neq \N$ implies that $\rb(\O)^{\perp} \neq \emptyset$.
\end{remark}

Below, we adopt the notation established in \Cref{collapse: D}.  Furthermore,  $\collapse{A}$ (respectively, $\collapse{X}$) is the collapse of $A$ (respectively, a set $X$) along $\O$.


\begin{remark}
\label{collapse of a defining vector: R}
If $\vv{a} \in \RR^d$ defines $\O$ in $\N$, then the standard basis vectors in $\rb(\O)^{\perp}$ correspond to the nonzero coordinates of $\vv{a}$.  Consequently, $\iprod{\vv{a}}{\vv{c}} = \iprod{\collapse{\vv{a}}}{\collapse{\vv{c}}}$ for every $\vv{c} \in \RR^d$.
\end{remark}

\begin{remark}
\label{collapse of monomial is monomial: R}
The collapsed matrix $\collapse{A}$ is monomial.  Indeed, each row of $\collapse{A}$ is a row of $A$, and hence is nonzero.   On the other hand, if $\vv{a} \in \RR^d$ defines $\O$, then \Cref{collapse of a defining vector: R} implies that the inner product of $\collapse{\vv{a}}$ with every column of $\collapse{A}$ is at least one.  In particular, the columns of $\collapse{A}$ are nonzero.
\end{remark}


%\begin{remark}[Collapsed programs]
%\label{collapsed programs: R}
%Throughout this article, we will compare linear and integer programs with analogous systems of constraints defined by $A$ and $\collapse{A}$ (e.g., $\LP(A, \vv{u})$ and $\LP(\collapse{A}, \collapse{\vv{u}})$, and $\IP(A, \vv{u})$ and $\IP(\collapse{A}, \collapse{\vv{u}})$).  
%
%By construction, $A$ and $\collapse{A}$ have the same number of columns, and so the feasible sets of these programs live in the same Euclidean space.   Furthermore, as $\collapse{A}$ is obtained by $A$ by omitting some its rows, the constraints imposed by $\collapse{A}$ in the above programs are a subset of those imposed by $A$.  Of course, these programs will differ only when $\O$ is unbounded.  
%\end{remark}


\begin{lemma}
\label{collapse of Newton polyhedron: L} 
If $\M$ is the Newton polyhedron in the coordinate subspace $\rs(\O)^{\perp}$ associated to the monomial matrix $\collapse{A}$, then $\collapse{\O}$ is a bounded face of $\M = \collapse{\N}$.    In addition, if $\vv{a} \in \RR^d$ defines $\O$ in $\N$, then $ \collapse{\vv{a}}$ defines $\collapse{\O}$ in $\M$. 
\end{lemma}

\begin{proof}
By definition, the Newton polyhedron $\M$ equals
%
\[  \conv( \col(\collapse{A}) ) + \cone(\rb(\O)^{\perp}) =  \collapse{\conv( \col(A))} + \collapse{\cone(\vv{e}_1, \ldots, \vv{e}_d)} =  \collapse{\N}.\]

Given \Cref{collapse of a defining vector: R}, it is not difficult to verify that $\collapse{\vv{a}}$ defines $\collapse{\O}$ in $\M$ whenever $\vv{a} \in \RR^d$ defines $\O$ in $\N$.  The positivity of $\collapse{\vv{a}}$ in $\rs(\O)^{\perp}$ then implies that $\collapse{\O}$ is bounded.  Alternatively, one may project \eqref{face: e} to $\rs(\O)^{\perp}$ to see that the collapsed face $\collapse{\O}$ equals $\conv( \collapse{ \col(A) \cap \O}) = \conv( \col(\collapse{A}) \cap \collapse{\O})$.  
\end{proof}



\newpage



\section{Linear programs associated to monomial pairs}


\begin{definition}
A \emph{monomial pair} $(A, \vv{u})$ consists of a monomial matrix $A$ and a positive point $\vv{u}$ in the range lattice of $A$.
\end{definition}


\begin{definition}
$\LP(A, \vv{u})$ is the linear program in $\RR^n$ defined as follows:
\begin{enumerate}
\item The constraints are $\vv{k} \geq \vv{0}$ and $A \vv{k} \leq \vv{u}$.
\item The objective function is $\vv{k} \mapsto \norm{\vv{k}}$.
\end{enumerate}
\end{definition}

\comment[inline]{The objective of this section is to connect this program to $F$-thresholds, and to study the optimal set of this linear program.  }



\subsection{Relations with $F$-thresholds}
\label{opt sets: SS}

\begin{definition}
The \emph{$F$-threshold} of a monomial pair $(A, \vv{u})$ is the unique positive real number $\ft{A}{\vv{u}} = \lambda$ with the property that  \[ (1/\lambda)  \cdot \vv{u}  \] 
lies in the boundary of the Newton polytope of $A$.  
\end{definition}

\begin{definition}
$\mf(A, \vv{u})$ is the minimal\footnote{Recall that the intersection of two faces of $\N$ is also a face of $\N$. Thus, as minimality here is with respect to inclusion, it follows that there is a unique such minimal face.} face $\mf(A, \vv{u})$ of the Newton polyhedron of $A$ containing the scaled point $(1/\lambda) \cdot \vv{u}$, where $\lambda = \ft{A}{\vv{u}}$.
\end{definition}


\begin{remark}  The positivity of $\vv{u}$ implies that $\ft{A}{\vv{u}}$ is well-defined, and that $\O = \mf(A, \vv{u})$ is a standard face of the Newton polyhedron of $A$.
\end{remark}

\begin{proposition}
\label{FT descriptions: P}
  If $\N$ is the Newton polyhedron in $\RR^d$ associated to a monomial matrix $A$ with $d$ rows, then
\[ \ft{A}{\vv{u}} = \min_{\vv{d}} \, \iprod{\vv{d}}{\vv{u}} = \iprod{\vv{c}}{\vv{u}} = \val \LP(A, \vv{u}) \] where the min is over all points $\vv{d} \in \RR^d$ that define a standard face of $\N$, and $\vv{c} \in \RR^d$ is any point that defines a face of $\N$ containing $\mf(A, \vv{u})$. 
\end{proposition}

\alert[inline]{Will need to connect this to $F$-thresholds of ideals}

\begin{proof}
   Let $\O$ be a face of $\N$ containing $\mf(A,\vv{u})$, and fix $\vv{c} \in \RR^d$ defining $\O$ in $\N$.
   Set $\lambda = \ft{A}{\vv{u}}$.
   By definition, $\vv{u} \in \lambda \O$, and so $\iprod{\vv{c}}{\vv{u}} = \lambda$.    Similarly, if $\vv{d}$ defines a standard face of $\N$, then $\vv{u} \in \lambda \N$ implies that $\iprod{\vv{d}}{\vv{u}} \geq \lambda$.

It remains to show that $\val \LP(A, \vv{u}) = \lambda$.  Towards this, note that if $\vv{s}$ is feasible for $\LP = \LP(A, \vv{u})$, then $A \vv{s} \leq \vv{u}$, and the nonnegativity of $\vv{c}$ then implies that  $\iprod{\vv{c}}{A \vv{s}} \leq \iprod{\vv{c}}{\vv{u}} = \lambda$.  Furthermore, the fact that $\vv{s} \geq \vv{0}$ and that the inner product of $\vv{c}$ with any column of $A$ is at least one implies that $\iprod{\vv{c}}{A \vv{s}}$ is at least $\norm{\vv{s}}$.  We conclude that $\val \LP \leq \lambda$.  

On the other hand, \eqref{face: e} and our choice of $\O$ imply that 
\begin{equation}
\label{cone containment: e}
 (1/\lambda) \cdot \vv{u} \in \O = \conv(\col(A) \cap \O) + \cone(\rb(\O)).
\end{equation}
Multiplying by $\lambda$, we obtain an expression $\vv{u} = A \vv{s} + \vv{w}$ with $\norm{\vv{s}} = \lambda$ and $\vv{w} \geq \vv{0}$.
Evidently, the point $\vv{s}$ is feasible for $\LP$, and so $\val \LP \geq \lambda$.
\end{proof}


The following is a consequence of the discreteness of the $F$-jumping exponents associated to an ideal in a regular ring \cite[Theorem~3.1]{blickle+mustata+smith.discr_rat_FPTs}.
However, to keep our discussion self-contained, we include an elementary proof in our specialized setting.


\begin{lemma}
\label{discreteness: L}
Given a monomial matrix $A$ and a real number $\beta > 0 $, there are only finitely many numbers of the form $\ft{A}{\vv{u}}$ less than $\beta$.    
%In particular, once $A$ is fixed, there are only finitely many numbers of the form $\ft{A}{\vv{u}}$ with $(A, \vv{u})$ very small.
\end{lemma}

\begin{proof}   
It suffices to show that there are only finitely many numbers $\ft{A}{\vv{u}}$ less than $\beta$ with $\mf(A, \vv{u}) = \O$ being fixed.   Consider such a pair, and let $\collapse{A}$ (respectively, $\collapse{X}$) be the collapse of $A$ (respectively,  a set $X$) along $\O$.

Note that if $\vv{a}$ defines $\O$, then \Cref{FT descriptions: P} tells us that 
%
\begin{equation} 
\label{ft inner product identity: e}
\ft{A}{\vv{u}} = \iprod{\vv{a}}{\vv{u}} = \iprod{\collapse{\vv{a}}}{\collapse{\vv{u}}}. 
\end{equation}
% 

The inequality $\ft{A}{\vv{u}} < \beta$ then implies that the collapsed point $\collapse{\vv{u}}$ must lie in the set of all $\vv{w} \in \rs(\O)^{\perp}$ with $\vv{w} > \vv{0}$ and $\iprod{\collapse{\vv{a}}}{\vv{w}} < \beta$.  However, the positivity of $\collapse{\vv{a}}$ in $\rs(\O)^{\perp}$ implies that this polyhedron is bounded (e.g., one may argue as in the proof of \Cref{bounded polytope: L}).  

In summary, as $\vv{u}$ varies through all points with  $\mf(A, \vv{u}) = \O$ and $\ft{A}{\vv{u}}$ less than $\beta$, the collapsed point $\collapse{\vv{u}}$ obtains only finitely values, and so the same must be true for the right-hand side of \eqref{ft inner product identity: e} above.
\end{proof}


The identity \eqref{cone containment: e} above implies that 
 %
%\[ \vv{u} \in \cone (\O) = \cone \left( (\col(A) \cap \O) \cup \rb(\O)  \right). \]
$\vv{u}$ is a convex combination of the columns of $A$ lying in $\O$ and the points in the recession basis of $\O$.  Typically, there are many ways to express $\vv{u}$ as such a convex combination, and as we see below, each such expression determines an optimal point of $\LP(A, \vv{u})$.

\begin{corollary}  
\label{opt set: C}
A point $\vv{s} \in \RR^n$ is optimal for $\LP(A, \vv{u})$ if and only if it satisfies the following conditions.
\begin{enumerate}
\item  \label{mc coords: e} The coordinates of $\vv{s}$ are nonnegative, and the $i$-th coordinate of $\vv{s}$ is zero whenever the $i$-th column of $A$ is not contained in $\O = \mf(A, \vv{u})$.
\item  \label{mc decomposition: e} $\vv{u} = A \vv{s} + \vv{w}$ for some $\vv{w} \in  \cone(\rb(\O))$.   
%\item  \label{mc sum: e}$\norm{\vv{s}} = \ft{A}{\vv{u}}$.
\end{enumerate}
\end{corollary}

\begin{proof}  
Set $\LP = \LP(A, \vv{u})$ and $\lambda = \val \LP$, and fix $\vv{a} \in \RR^d$ that defines the face $\O = \mf(A, \vv{u})$ in the Newton polyhedron associated to $A$. 

First, note that any point $\vv{s}$ satisfying the two conditions above must be feasible for $\LP$, and so it suffices to show that $\norm{\vv{s}} = \lambda$.
Towards this, the assumption on $\vv{w}$ in the expression $\vv{u} = A \vv{s} + \vv{w}$ implies that $\iprod{\vv{a}}{\vv{w}} = 0$, which allows us to compute that $\lambda = \iprod{\vv{a}}{\vv{u}} = \iprod{\vv{a}}{A\vv{s}} = \norm{\vv{s}}$, where the first equality follows from 
\Cref{FT descriptions: P}, and the last from the assumption on the coordinates of $\vv{s}$ and the fact that the inner product of $\vv{a}$ with every column of $A$ contained in $\O$ is one.

Next, suppose that $\vv{s}$ is optimal for $\LP$, and let $\vv{w}$ be the unique point in $\RR^d$ with $\vv{u} = A \vv{s} + \vv{w}$.  The optimality of $\vv{s}$ implies that $\norm{\vv{s}} = \lambda$, while the constraints of $\LP$ imply that $\vv{w} \geq \vv{0}$.  A direct computation shows that
%
\[ \lambda = \iprod{\vv{a}}{\vv{u}} = \iprod{\vv{a}}{A \vv{s}} + \iprod{\vv{a}}{\vv{w}} \geq \norm{\vv{s}} + \iprod{\vv{a}}{\vv{w}} = \lambda + \iprod{\vv{a}}{\vv{w}} \]
%
which allows us to conclude that $\iprod{\vv{a}}{A \vv{s}} = \norm{\vv{s}}$ and $\iprod{\vv{a}}{\vv{w}} = 0$.
It follows from these identities, and the fact that the standard basis vectors in $\rb(\O)^{\perp}$ correspond to the positive coordinates of $\vv{a}$, that the point $\vv{s}$ must satisfy the two asserted conditions.
\end{proof}



\begin{theorem}  
\label{uniform denominators for vertices:  T}
Given a monomial matrix $A$, there exists a positive integer $\denom = \denom(A)$ such that for every monomial pair $(A, \vv{u})$, every vertex of $\opt \LP(A, \vv{u})$ is rational with denominator $\denom$.
\end{theorem}

\begin{proof}

Fix a pair $(A, \vv{u})$. Set $\LP = \LP(A, \vv{u})$ and $\O = \mf(A, \vv{u})$.  Let $M$ be the matrix obtained from $A$ by omitting any columns not in $\O$, and inserting as a column each standard basis vector in $\rb(\O)$.  Finally, let $\denom = \denom(\O)$ be the least common multiple of all the nonzero minors of $M$.

If $\Q$ is the polyhedron consisting of all $\vv{t}$ in the domain of $M$ with $\vv{t} \geq \vv{0}$ and $M \vv{t} = \vv{u}$, then \Cref{opt set: C} implies that there exists a linear bijection $\opt \LP 
\leftrightarrow \Q$.  Furthermore, if $\vv{t}^{\ast}$ is a vertex of $\Q$, then \Cref{vertex: L} allows us to solve for the nonzero coordinates of $\vv{t}^{\ast}$ in the equation $M \vv{t}^{\ast} = \vv{u}$.  In particular, the fact that $\vv{u}$ has integer coordinates implies that the nonzero coordinates of $\vv{t}^{\ast}$ are rational with denominator $\denom = \denom(\O)$.  The linear bijection $\opt \LP \leftrightarrow \Q$ implies the same must be true for every vertex of $\opt \LP$.

Our assertion then follows from the observation that since $A$ is fixed, as $(A, \vv{u})$ varies, there are only finitely many possibilities for $\O = \mf(A, \vv{u})$.
\end{proof}


\subsection{Minimal coordinates}

\ \daniel[inline]{The idea is that a minimal coordinate is a special kind of optimal point.  Maybe we should call it a \emph{distinguished optimal point}, or something similar (\emph{optimal coordinate}?), to emphasize this.  I am kinda worried about calling a point a coordinate.  The only time we need to distinguish between a minimal coordinate and optimal point is when the corresponding minimal face is not bounded.
   \emily[inline]{special point?}
   \pedro[inline]{I like ``special point''.}
}


\comment[inline]{Minimal coordinates are how we construct canonical solutions to the integer program $\IP(A, \vv{u}q)$;  see \Cref{canonical-feasible: T} for more details.}

Technicalities that arise in future sections whenever $\mf(A, \vv{u})$ is unbounded force us to consider a certain distinguished subset of optimal points, in which we require a strengthening of condition \eqref{mc decomposition: e} in \Cref{opt set: C}.


\begin{definition}
\label{mc: D} 
Let $\O = \mf(A, \vv{u})$.  A point $\vv{s}$ is a \emph{minimal coordinate} for $(A, \vv{u})$ if it satisfies the following conditions.
\begin{enumerate}
\item $\vv{s} \in \opt \LP(A, \vv{u})$.
\item $\vv{u} = A \vv{s} + \vv{w}$ for some $\vv{w}$ in the relative interior of $\cone ( \rb(\O))$.  
\end{enumerate}

The set of all such points is denoted $\mc(A, \vv{u})$, and the set of all such points with rational coordinates is denoted $\mc_{\QQ}(A, \vv{u})$.  
\end{definition}

%We see below that $\mc(A, \vv{u})$ and $\opt \LP(A, \vv{u})$ are equal, or close to equal.

\begin{proposition}  
\label{opt versus mc: P}  If $\O = \mf(A, \vv{u})$ is bounded, then $\mc(A, \vv{u}) = \opt \LP(A, \vv{u})$.  Otherwise,  $\mc(A, \vv{u})$ is a nonempty convex subset of $\opt \LP(A, \vv{u})$ that contains the relative interior of this optimal set. 
\end{proposition}

\begin{proof}    
If $\O$ is bounded, then $\rb(\O) = \emptyset$, and so $\cone( \rb(\O)) = \{\vv{0} \}$ is equal to its relative interior.  Next, set $\lambda = \ft{A}{\vv{u}}$ and assume that $\O$ is unbounded.

 The minimality of $\O$ implies that $(1/\lambda)  \cdot \vv{u}$ cannot lie in any proper face of $\O$, and therefore, must lie in its relative interior.  Further, as the relative interior operation on convex sets commutes with Minkowski sums---see, \eg \cite[Theorem 4.10(b)]{van-tiel.convex-analysis}---the decomposition in \eqref{face: e}  implies that $\vv{u} = \vv{v} + \vv{w}$ with $\vv{v} \in \lambda \conv(\col(A) \cap \O)$ and $\vv{w} \in \ri \cone(\rb(\O))$.  Any realization of $\vv{v}$ as $\lambda$ times a convex combination of the points in $\col(A) \cap \O$ then determines a minimal coordinate.

We have just shown that $\mc(A, \vv{u})$ is nonempty, and it is clear that this set is convex.  Next,  suppose that $\vv{e}_i \in \rb(\O)$.  If every vertex $\vv{s}$ of the optimal set of $\LP = \LP(A, \vv{u})$ was such that $A \vv{s}$ agreed with $\vv{u}$ in the $i$-th coordinate, then the same would be true for every point in the optimal set.   However, the minimal coordinate constructed above shows that this is impossible.  Therefore, for every $\vv{e}_i \in \rb(\O)$, there exists a vertex $\vv{s}_i$ of $\opt \LP$ such that $A \vv{s}_i$ is less than $\vv{u}$ in the $i$-th coordinate.  Consequently, if $\vv{s}^{\ast}$ is any convex combination of these vertices of $\opt \LP$ with positive coefficients, it follows that $A \vv{s}^{\ast}$ is less than $\vv{u}$ in the coordinate subspace $\rs(\O)$.  
\end{proof}


\comment[inline]{An example in which these sets (the set of minimal coordinates, the optimal set, and the relative interior of the optimal set) all differ is commented out}

% Consider the monomial matrix \[ A = \begin{bmatrix} a & 0 & c \\ 0 & b & c \\ 0 & 0 & d \end{bmatrix} \] 
% where $a,b,c$ are positive integers with $1/a + 1/b = 1/c$ and $d$ is any integer with $d>c$.  The maximal face of the splitting polytope is the edge connecting the points \[ \left( \frac{d-c}{da}, \frac{d-c}{db}, \frac{1}{d} \right) \text{ and } \left( \frac{1}{a}, \frac{1}{b}, 0 \right).\]  On the other hand, it is easy to check that the minimal coordinates of $(A, \vv{1})$ consist of the points on this edge except for the first of these two  points.

\begin{definition}  Suppose that $A$ is a monomial matrix. A \emph{special denominator} for $A$ is a positive integer $\denom = \denom(A)$ such that for every pair $(A, \vv{u})$, there exists a point $\vv{s} \in \mc(A, \vv{u})$ so that $\denom \cdot \vv{s}$ has integer coordinates.
\end{definition}

\begin{theorem}  
\label{special-denominators-exist:  T}
Special denominators exist.
\end{theorem}


\begin{proof}
   Let $\ell_{\circ}$ be an integer satisfying the property described in \Cref{uniform denominators for vertices:  T} relative to $A$, and fix a pair $(A, \vv{u})$.
   If $\O = \mf(A, \vv{u})$ is bounded, then $\mc(A, \vv{u}) = \opt \LP(A, \vv{u})$ by \Cref{opt versus mc: P}, and so there is always a vertex in this set with denominator~$\ell_{\circ}$.

   Next, suppose $\O$ is unbounded, so that $A$ has $d \geq 2$ many rows.
   Without loss of generality, suppose that $\rb(\O) = \{ \vv{e}_1, \ldots, \vv{e}_c \}$ for some $1 \leq c \leq d-1$, and fix \emph{positive} integers $d_1, \ldots, d_c$ that sum to $d-1$.
   As demonstrated in the  proof of \Cref{opt versus mc: P}, for every index  $1 \leq i \leq c$, there exists a vertex $\vv{s}_i$ of $\opt \LP(A, \vv{u})$ for which $A \vv{s}_i$ is less than $\vv{u}$ in the $i$-th coordinate.
   It then follows from the definition of minimal coordinate that the point
   \[ \frac{ d_1 \cdot \vv{s}_1 + \cdots + d_c \cdot  \vv{s}_c}{d-1}  \]
   lies in $\mc_{\QQ}(A, \vv{u})$ and has denominator $(d-1)\ell_{\circ}$.  
\end{proof}


Below, we describe the relationship between collapses and the other notions introduced in this section.

\begin{corollary}
\label{collapse of mf and mc: C}
Consider a monomial pair $(A, \vv{u})$.  If $\collapse{A}$ \textup(respectively, $\collapse{X}$\textup) is the collapse of $A$ \textup(respectively, a set $X$\textup) along $\O = \mf(A, \vv{u})$, then the following hold.

\begin{enumerate}
\item $\mf(\collapse{A}, \collapse{\vv{u}}) = \collapse{\O}$ and $\ft{A}{\vv{u}} = \ft{\collapse{A}}{\collapse{\vv{u}}}$.
\item Each optimal point for $\LP(A, \vv{u})$ is also optimal for $\LP(\collapse{A}, \collapse{\vv{u}})$.  
\item Each minimal coordinate of $(A, \vv{u})$ is a minimal coordinate of $(\collapse{A}, \collapse{\vv{u}})$.
\end{enumerate}
\end{corollary}

\begin{proof}
Set $\lambda = \ft{A}{\vv{u}}$, so that $(1 / \lambda) \cdot \vv{u}$ lies in the relative interior of $\O$.  It is clear that projection preserves relative interiors, and so $(1/\lambda) \cdot \collapse{\vv{u}}$ must lie in the relative interior of $\collapse{\O}$, which is a bounded face of $\collapse{\N}$ by \Cref{collapse of Newton polyhedron: L}.  This observation demonstrates both that $\collapse{\O}$ is the minimal face of $\collapse{\N}$ containing $(1/\lambda) \cdot \collapse{\vv{u}}$, and that $\lambda = \ft{\collapse{A}}{\collapse{\vv{u}}}$.  

Next, note that \Cref{FT descriptions: P} and the above tells us that \[ \val \LP(A, \vv{u}) = \ft{A}{\vv{u}} = \ft{\collapse{A}}{\collapse{\vv{u}}} = \val \LP(\collapse{A}, \collapse{\vv{u}}). \] 
%
By construction, each row of $\collapse{A}$ is a row of $A$, and so the constraints of $\LP(\collapse{A}, \collapse{\vv{u}})$ are a subset of those of $\LP(A, \vv{u})$.  It follows that any optimal point for $\LP(A, \vv{u})$ must be optimal for $\LP(\collapse{A}, \collapse{\vv{u}})$.  The boundedness of $\collapse{\O}$, \Cref{opt versus mc: P}, and the preceding observation then allows us to conclude that
\[ \mc(A, \vv{u}) \subseteq \opt \LP(A, \vv{u}) \subseteq \opt \LP(\collapse{A}, \collapse{\vv{u}}) = \mc(\collapse{A}, \collapse{\vv{u}}).\] 
\end{proof}




\newpage
\section{An auxiliary integer program}

\

\begin{definition}
$\IP(A, \vv{u})$ is the integer program in $\ZZ^n$ defined as follows:
\begin{enumerate}
\item The constraints are $\vv{k} \geq \vv{0}$ and $A \vv{k} < \vv{u}$. 
\item The objective function is $\vv{k} \mapsto \norm{\vv{k}}$.
\end{enumerate}
\end{definition}

\emily[inline]{Note somewhere that the feasible set of $\IP$ is bounded:  This is used in the fractal linear program later on.}

\begin{definition}
The \emph{image} of $\IP(A, \vv{u})$ is the set \[ \im \IP(A, \vv{u}) = A ( \opt \IP(A, \vv{u}) ). \] 
\end{definition}

% \comment[inline]{Our objective is to study $\IP(A, \vv{u}q)$ whenever $q = p^e$ and $p \gg 0$.}

% \daniel[inline]{We ``solve" the program $\IP(A, \vv{u}q)$ as is done in the other paper, or as discussed at AIM.  We recall the rough outline below.
% \begin{enumerate}
% \item Step 1:  Construct a canonical feasible point that depends on $p$.   This step is more involved in this paper, as compared to the other one, and to what we did at AIM.  The extra complexity comes from the fact that there may be many minimal coordinates, whereas in each of those other cases, there is a unique one.  In any case, we associate to each minimal coordinate for $(A,\vv{u})$ a canonical feasible point for $\IP(A, \vv{u}q)$.  This will be done in \Cref{canonical-feasible: T}.
% \item Step 2:  Fix a minimal coordinate for $(A, \vv{u})$.  Use it to construct a feasible point for $\IP(A, \vv{u}q)$.  Consider an arbitrary feasible point $\vv{k}$ for $\IP(A, \vv{u}q)$, and consider the difference $\vv{h} = \vv{k} - $(canonical feasible point). Translate the constraints on $\vv{k}$ into ones on $\vv{h}$.  This (and more) is done in \Cref{relating-programs: ss}.  Use the resulting inequalities to define a \emph{secondary integer program}.  The secondary program that results from this process is the one $\ip$ appearing in \Cref{aux program: D}.
% \item Step 3:  Study the finiteness properties of $\ip$.  This is done in this section, before the connection between $\IP$ and $\ip$ is discussed, since these finiteness properties of $\ip$ are called upon to tie down the connection with $\IP$.  The downside is that this order of things makes things here seem really unmotivated.
% \item Step 4:  Establish that all of the interesting objects that appear in this process do not depend on the choice of minimal coordinate we picked in Step 2.  This is kind of technical (I bet there is a cleaner way to see this), and is done in \Cref{useful-invariants: ss}.
% \end{enumerate}
% }



\todo[inline]{Relate $\IP$ to $\nu$'s and leftovers of $\ideala^{[\nu]}$.}

\subsection{Canonical feasible points}  We highlight a simple construction that associates to any point in $\mc_{\QQ}(A, \vv{u})$ a feasible point for $\IP(A, \vv{u}, q)$.  As a part of this construction, we call upon some basic notions from number theory.   

\begin{definition} If $m,n \in \ZZ$ are positive, then $\lpr{m}{n}$ is the \emph{least positive residue} of $m$ modulo $n$, i.e.,  and $m \equiv \lpr{m}{n} \bmod n$ and $1 \leq \lpr{m}{n} \leq n$.
\end{definition}

\begin{definition}
\label{tail: D}
Suppose that $\lambda \in \QQ$ is nonnegative and $q \in \ZZ$ is positive.   If $\lambda = \frac{a}{b}$ for some \emph{positive} integers $a$ and $b$, then we define\footnote{It is clear that this expression depends only on $\lambda$, but not on the integers $a$ and $b$.}
\[ \tail{\lambda}_q = \frac{ \lpr{aq}{b}}{b}. \] 
%
We set $[0]_q = 0$, and if $\vv{s} \in \QQ^n$ satisfies $\vv{s} \geq \vv{0}$, then we define $\tail{\vv{s}}_q$ to be the point in $\QQ^n$ obtained by applying this operation to each coordinate of $\vv{s}$.
\end{definition}

\begin{remark}
\label{tail-basics: R}
Suppose that $\lambda \in \QQ$ and $q \in \ZZ$ are both positive, and write $\lambda = \frac{a}{b}$ with $a$ and $b$ positive integers.  Then $\tail{\lambda}_q$ is positive and rational, at most $1$,  and depends on  $q$ modulo $b$, but not on $q$ itself.  Furthermore, 
%
\[ \lambda q - \tail{\lambda}_q = \frac{aq-\lpr{aq}{b}}{b} \] is an integer, and in fact, is the \emph{greatest integer less than $\lambda q$}.
\end{remark}


\begin{lemma}
   \label{less than u: L}  Suppose that $\vv{s}$ is a minimal coordinate for a pair $(A, \vv{u})$.
   If $\vv{t}$ is a point in the domain of $A$ with $\vv{0} \leq \vv{t} \leq \vv{s}$, with the latter bound strict in every coordinate in which $\vv{s}$ is positive, then $A \vv{t} < \vv{u}$.
\end{lemma}

\begin{proof}  Set $\O = \mf(A, \vv{u})$.  The fact that $\vv{s} \in \mc(A, \vv{u})$  implies that \[ \vv{u} = A \vv{s} + \vv{w}\] for some positive point $\vv{w}$ in $\rs(\O)$.     The inequality $\vv{t} \leq \vv{s}$ induces the bound $A \vv{t} \leq A \vv{s} = \vv{u} - \vv{w}$, which shows that $A\vv{t}$ is less than $\vv{u}$ after projecting to the coordinate subspace $\rs(\O)$.  To conclude the proof, it suffices to show that the same is true in the complementary subspace $\rs(\O)^{\perp}$.  

Towards this, let $(\collapse{A},\collapse{\vv{u}})$ be the collapse of $(A,\vv{u})$ along $\O$.  Our choice of $\vv{t}$ implies that $\collapse{A}( \vv{s} - \vv{t})$ and $\collapse{A} \vv{s} = \collapse{\vv{u}}$ are both linear combinations with positive coefficients of the same set of columns of $\collapse{A}$.  Therefore, since $\collapse{\vv{u}} = \collapse{A} \vv{s}$ is positive in $\rs(\O)^{\perp}$, then the same must be true for $\collapse{A}(\vv{s} - \vv{t})$.  In other words, $\collapse{A} \vv{t} < \collapse{A} \vv{s} = \collapse{\vv{u}}$, which shows that $A \vv{t} < \vv{u}$ in $\rs(\O) \oplus \rs(\O)^{\perp}$.
\end{proof}


%A crucial notion in our upcoming arguments is the following basic construction from elementary number theory.
%
%\begin{definition}  If $\lambda \in \QQ$ is nonzero and $q$  is a positive integer, we set \[ \tail{\lambda}_q = \frac{ \lpr{aq}{b}}{b} \] where $\lambda = a/b$ is some representation for $\lambda$ and $\lpr{c}{b}$ is the least \emph{positive} residue of the integer $c$ modulo $b$.   In the case that $\lambda = 0$, we set $\tail{\lambda}_q = 0$.  We extend this definition to points of $\QQ^n$ in a coordinate-wise manner.
%\end{definition}
%
%\begin{remark} This definition is clearly independent of the representation of $\lambda \neq 0$ as a fraction.  In fact, in this case, the positive rational number $\tail{\lambda}_q$ depends only on the residue of $q$ modulo the least denominator of $\lambda$.
%\end{remark}
%
%\begin{remark}  If $\vv{s} \in \QQ^n$ has nonnegative coordinates, then \[ \vv{s}q - \tail{\vv{s}}_q \] has nonnegative integer coordinates for every positive integer $q$.  We will use this fact often in the sequel, typically without explicitly mentioning it.
%\end{remark}



%One again, suppose $(A, \vv{u})$ is a monomial pair and that $q$ is a positive integer.  


\begin{theorem}
\label{canonical-feasible: T}
If $\vv{s} \in \mc_{\QQ}(A, \vv{u})$ and $q \in \ZZ$ is positive, then  \[ \vv{s}q - \tail{\vv{s}}_q \in \feas \IP(A, \vv{u}, q).\] 
\end{theorem}

\begin{proof}  \Cref{tail-basics: R} tells us that if $\vv{t} = \vv{s} - (1/q) {\tail{\vv{s}}_q}$, then $\vv{t}q = \vv{s}q -\tail{\vv{s}}_q$ has nonnegative integer coordinates.  In fact, \Cref{tail-basics: R} also allows us to apply \Cref{less  than u: L} with $\vv{t}$ as defined here to see that $A (\vv{s} q - \tail{\vv{s}}_q ) =  A\vv{t}q <  \vv{u}q$.  
\end{proof}

%To clarify the statements of the results that follow, we fix the following notation.

%\begin{setup}
%\label{collapse: S}
%Let $(A, \vv{u})$ be a $d \times n$ monomial pair with $\O = \mf(A, \vv{u})$.  Let $\collapse{X}$ denote the collapse of a subset $X$ of $\RR^d$ along the face $\O$, and let $\collapse{A}$ be the collapse of $A$ along $\O$.  With these conventions, $\collapse{A \vv{t}} = \collapse{A} \vv{t}$ for every $\vv{t} \in \RR^n$.    
%\end{setup}
%
%\begin{remark}  The main upshot to working with the collapsed matrix $\collapse{A}$ is the following observation:  If $\vv{s} \in \mc(A, \vv{u})$, then though it is not necessarily true that $A \vv{s}$ equals $\vv{u}$, it will always be the case that 
%\[ \collapse{A} \vv{s} = \collapse{A \vv{s}} = \collapse{\vv{u}}.\] 
%\end{remark}



%\subsection{A critical secondary linear program}  We continue to adopt the notation in \Cref{collapse: S}.  Below, we define and study a secondary integer program that will play a key role in our solution of $\IP(A, \vv{u}q)$ for $q \gg 0$.
%
%
%\begin{definition} If $\vv{s} \in \mc_{\QQ}(A, \vv{u})$ and $q>0$ is an integer, then
%\[ \ip_q(A, \vv{u}, \vv{s}) \] 
%is  the integer program  in $\ZZ^n$ is defined as follows:
%\begin{enumerate}
%\item The objective function is $\vv{k} \mapsto \norm{\vv{k}}$.
%\item The constraints are that the $i$-th coordinate of $\vv{k}$ is nonnegative whenever the $i$-th coordinate of $\vv{s}$ is zero, and that $\collapse{A} \vv{k}  < \collapse{A} \tail{\vv{s}}_q$.
%\end{enumerate}
%
%The \emph{image} of $\ip_q(A, \vv{u}, \vv{s})$ is the subset of $\ZZ \rb(\O)^{\perp}$ given by \[ \im \ip_q(A, \vv{u}, \vv{s})  = \collapse{A} (\opt \ip_q(A, \vv{u}, \vv{s})). \] 
%\end{definition}
%
%Before establishing the basic properties of these programs, we establish their relevance to the problem at hand.

%\emily[inline]{The following could be discussion in the prose that leads to the definition of $\Theta$. }
%\daniel[inline]{I'm giving this a shot below.}

\begin{remark}[Comparisons with canonical feasible points] 
\label{comparison: R}
Adopt the context of \Cref{canonical-feasible: T}, and fix a point $\vv{k}$ that is feasible for $\IP = \IP(A, \vv{u}, q)$.    

Our goal is to describe some natural constraints on the difference between $\vv{k}$ and the feasible point  described in \Cref{canonical-feasible: T}.  Toward this, set 
%
\[ \vv{h} =  \vv{k} - \vv{s}q + \tail{\vv{s}}_q \]   
%
and, let $\collapse{\mathcal{X}}$ denote the collapse of $\mathcal{X}$ along the face $\O = \mf(A, \vv{u})$.  


Notice that if $s_i = 0$, then $h_i  = k_i \geq 0$, where the last bound follows from the nonnegativity constraint of $\IP$.  The definition of $\vv{h}$ and constraints of $\IP$ also tell us that $A ( \vv{s}q-\tail{\vv{s}}_q + \vv{h}) = A \vv{k} < \vv{u}q = A \vv{s}q + \vv{w}q$, where $\vv{w} \in \rs(\O)$ is as in \Cref{mc: D}.  Collapsing this inequality, keeping in mind that $\collapse{\vv{w}} = \vv{0}$, and rearranging terms, shows that $\collapse{A \vv{h}} < \collapse{A \tail{\vv{s}}_q}$.
\end{remark}




\subsection{Another integer program}


\begin{definition}
A monomial \emph{list} $(A, \vv{u}, \vv{s}, q)$ consists of the following data.
\begin{enumerate}
\item A monomial pair $(A, \vv{u})$.
\item A rational minimal coordinate $\vv{s} \in \mc_{\QQ}(A, \vv{u})$.
\item A positive integer $q$.
\end{enumerate}
\end{definition}

We call a list whose first term is the matrix $A$ an $A$-list.

%\begin{definition}  If $A$ is a monomial matrix, then 
%\[ \lis(A) \] is the set of all lists whose first term is $A$.  We call such a list an $A$-list.
%\end{definition}


\begin{definition}  
\label{aux program: D}
If $(A, \vv{u}, \vv{s}, q)$ is a monomial list, then
\[ \ip(A, \vv{u}, \vv{s}, q) \] 
is the integer program in domain lattice of $A$ defined as follows:
\begin{enumerate}
\item The objective function is $\vv{h} \mapsto \norm{\vv{h}}$.
\item The constraints are that the $i$-th coordinate of $\vv{h}$ is nonnegative whenever the $i$-th coordinate of $\vv{s}$ is zero, and that \[ \collapse{A \vv{h}}  < \collapse{A \tail{\vv{s}}_q}\]
\daniel{We should remind the reader that the collapsed inequalities are a subset of the ones determined by $A$} where $\collapse{\mathcal{X}}$ is the collapse of $\mathcal{X}$ along the face $\O = \mf(A, \vv{u})$.\end{enumerate}
\end{definition}


\begin{definition}
The \emph{image} of $\ip(A, \vv{u}, \vv{s}, q)$ is the set \[ \im \ip(A, \vv{u}, \vv{s}, q)  =  \collapse{A (\opt \ip(A, \vv{u}, \vv{s}, q))}\] 
where $\collapse{\mathcal{X}}$ is the collapse of $\mathcal{X}$ along the face $\O = \mf(A, \vv{u})$.
\end{definition}

\begin{proposition}  
\label{comparison: P}
If $(A, \vv{u}, \vv{s}, q)$ is a list, then $\feas \IP(A, \vv{u}, q)$ lies in 
\[ \vv{s}q - \tail{\vv{s}}_q + \feas \ip (A, \vv{u}, \vv{s}, q).\]
\end{proposition}

\begin{lemma}
\label{tail projection: L}
If $(A, \vv{u}, \vv{s}, q)$ is a list and $\O = \mf(A, \vv{u})$, then $\collapse{A}\tail{\vv{s}}_q$ is a positive lattice point in $\rs(\O)^{\perp}$, where $\collapse{A}$ is the collapse of $A$ along $\O$.
\end{lemma}

\begin{proof}  By construction, $\vv{s}q - \tail{\vv{s}}_q $ has nonnegative integer coordinates, and the identity 
$\collapse{\vv{u}} q =\collapse{A} \vv{s} q = \collapse{A} ( \vv{s}q - \tail{\vv{s}}_q ) +\collapse{A} \tail{\vv{s}}_q$ then shows that $\collapse{A} \tail{\vv{s}}_q$ must also have integer coordinates.   To see that this vector is positive in $\rs(\O)^{\perp}$, note that $\collapse{\vv{u}} = \collapse{A} \vv{s}$ and $\collapse{A} \tail{\vv{s}}_q$ are both linear combinations with positive coefficients of the same set of columns of $\collapse{A}$.  Given this, it is easy to see that since $\collapse{\vv{u}} = \collapse{A} \vv{s}$ is positive in $\rs(\O)^{\perp}$, the same must be true for $\collapse{A} \tail{\vv{s}}_q$.
\end{proof}


\begin{remark}
\label{collapsed aux program: R}
Suppose $(A, \vv{u}, \vv{s}, q)$ is a list.  If $(\collapse{A}, \collapse{\vv{u}})$ is the collapse of $(A ,\vv{u})$ along $\O = \mf(A, \vv{u})$, then \Cref{collapse of mf and mc: C} implies that 
\[ (\collapse{A}, \collapse{\vv{u}}, \vv{s}, q) \] is also a monomial list.  It is then clear from \Cref{aux program: D} that 
\[ \ip(A, \vv{u}, \vv{s}, q) = \ip(\collapse{A}, \collapse{\vv{u}}, \vv{s}, q). \] 
\end{remark}



The following may be regarded as a partial converse to \Cref{comparison: R}

\emily[inline]{Restate as a lemma first.  Do this point-by-point, and appeal to the finiteness of the $\mathbb{O}$.
We could say ``if $\vv{h}$ is optimal for $\Theta$, then $\ldots$ is optimal for $\ldots$''
}


\daniel[inline]{This has been changed to a ``point-by-point" statement.  This was necessary, since in its current placement, we haven't established any finiteness properties of $\ip$, and the old proof used $\mathbb{O}$}

\newpage
\begin{proposition}
\label{uniform value: P}
Given a list $(A, \vv{u}, \vv{s}, q)$ and point $\vv{h} \in \opt \ip(A, \vv{u}, \vv{s}, q)$, the point 
$\vv{s}q - \tail{\vv{s}}_q + \vv{h}$ is optimal for $\IP(A, \vv{u},q)$ whenever $q \gg 0$. 
\end{proposition}

\begin{proof} We start by describing what it means $q$ to be large.  Fix a positive denominator  $\denom \in \ZZ$ for $\vv{s} \in \mc_{\QQ}(A, \vv{u})$, and choose $q \gg 0$ so that $q/\denom$ is greater than every coordinate of $\vv{1} - \vv{h}$, and every coordinate of $A \vv{h}$.

Let $\collapse{\mathcal{X}}$ denote the collapse of $\mathcal{X}$ along $\O = \mf(A, \vv{u})$, and write  \[ \vv{u} = A \vv{s} + \vv{w} \] for some $\vv{w}$ that is positive in $\rs(\O)$, as in \Cref{mc: D}.  As $\vv{u}$ has integer coordinates, it follows that $\denom$ is also a denominator for $\vv{w}$.  

\Cref{tail-basics: R} tells us $\vv{k} := \vv{s}q - \tail{\vv{s}}_q + \vv{h}$ has integer coordinates, and we claim that $\vv{k} \geq \vv{0}$, that is, $\vv{s}q \geq \tail{\vv{s}}_q - \vv{h}$, whenever $q \gg 0$.  Indeed, if the $i$-th coordinate of $\vv{s}$ is zero, then so is the $i$-th coordinate of $\tail{\vv{s}}_q$, while the feasibility of  $\vv{h}$ for $\ip = \ip(A, \vv{u}, \vv{s}, q)$ implies that the $i$-th coordinate of $\vv{h}$ is nonnegative.  On the other hand, if the $i$-th coordinates of $\vv{s}$ is positive, then it must be at least $q/\denom$, and so the $i$-th coordinate of $\vv{s}q$ is at least $q/\denom$, which is greater than $1 - h_i$ by our choice of $q \gg 0$.  However, \Cref{tail-basics: R} also tells us that the $i$-th coordinate of $\tail{\vv{s}}_q - \vv{h}$ is at most $1-h_i$.  In summary, we have just shown that $\vv{k}$ is a nonnegative lattice point whenever $q \gg 0$.

Thus, $\vv{k}$ is feasible for $\IP = \IP(A, \vv{u}, q)$ if and only if
\[ A\vv{k} = A (\vv{s}q - \tail{\vv{s}}_q + \vv{h})  < \vv{u}q = A {\vv{s}}q + \vv{w}q.\] 
which we rewrite as 
\begin{equation} 
\label{equivalent ineq: e}
A \vv{h} < A \tail{\vv{s}}_q + \vv{w}q.
\end{equation}

After projecting to $\rs(\O)^{\perp}$, the bound \eqref{equivalent ineq: e} becomes $\collapse{A \vv{h}} < \collapse{A \tail{\vv{s}}}_q$, which holds by the feasibility of $\vv{h}$ for $\ip$.  If $\O$ is unbounded, then the projection of the right-hand side of \eqref{equivalent ineq: e} to $\rs(\O)$ is at least $\vv{w}q$.  However, as $\denom$ is a denominator for $\vv{w}$, every coordinate of $\vv{w}q$ is at least $q/\denom$,  and our choice of $q \gg 0$ then guarantees that \eqref{equivalent ineq: e} holds after projecting to $\rs(\O)$.  We conclude that \eqref{equivalent ineq: e} holds throughout $\RR^d = \rs(\O) \oplus \rb(\O)^{\perp}$.

In summary, we have just shown that $\vv{k}$ is feasible for $\IP(A, \vv{u}q)$, and so 
\[ \val \IP \geq \norm{\vv{k}} = \ft{A}{\vv{u}} \cdot q - \norm{\tail{\vv{s}}_q} + \val \ip \] 
where above we have used that $\vv{s} \in \mc_{\QQ}(A, \vv{u})$ and $\vv{h} \in \opt \ip$.  To establish the optimality of $\vv{k}$, it remains to show that the $\val \IP$ equals this lower bound.  However, this is a consequence of \Cref{comparison: P}.
\end{proof}




\subsection{Some finiteness properties}  
We now explore some finiteness properties, and our results are of two types:  \Cref{bounded value: L} and \Cref{finite image: C} concern the integer program $\ip$ associated to some fixed list,  while \Cref{finitely many secondary programs: L} and \Cref{finitely many coord sums: C} concern the nature of these programs as the list varies.

\begin{lemma}
\label{bounded value: L} 
If $(A, \vv{u}, \vv{s}, q)$ is a list, then $0 \leq  \val  \ip(A, \vv{u}, \vv{s}, q) < \norm{\tail{\vv{s}}_q}$.  
\end{lemma}

\begin{proof}   
Fix a point $\vv{a} \in \RR^d$ that defines $\O  = \mf(A, \vv{u})$, and let $\collapse{X}$ denote the collapse of a subset $X$ along $\O$.  Thus, if $\collapse{A}$ is the collapse of $A$ along $\O$, then
\[ \iprod{{\vv{a}}}{A \vv{t}} = \iprod{\collapse{\vv{a}}}{\collapse{A \vv{t}}} = \iprod{\collapse{\vv{a}}}{\collapse{A} \vv{t}} \] for every $\vv{t}$.  With this notation in hand, we begin the proof below.

The product $\vv{a}^{\mathrm{T}} A $ is a row vector whose $i$-th coordinate is the inner product of $\vv{a}$ with the $i$-th column of $A$ (and so is at least one).   In fact, if the $i$-th coordinate of a point $\vv{k}$ feasible for $\ip = \ip(A, \vv{u}, \vv{s}, q)$ were negative, then the $i$-th coordinate of $\vv{s}$ must be positive;  thus, the $i$-th column of $A$ must lie in $\O$, and so the $i$-th coordinate of $\vv{a}^{\mathrm{T}} A$ must equal one.  In particular, 
%
\begin{equation} 
\label{bound in inner product: e}
\norm{\vv{k}} \leq (\vv{a}^{\mathrm{T}} A) \vv{k} =  \vv{a}^{\mathrm{T}} (A \vv{k}) = \iprod{\vv{a}}{A \vv{k}} = \iprod{\collapse{\vv{a}}}{\collapse{A} \vv{k}} 
\end{equation}
whenever $\vv{k}$ is feasible for $\ip$, and a similar argument will show that 
\begin{equation}  
\label{norm of tail: e}
\norm{\tail{\vv{s}}_q} =  \iprod{\vv{a}}{A \tail{\vv{s}}_q} = \iprod{\collapse{\vv{a}}}{\collapse{A} \tail{\vv{s}}_q}.
\end{equation}

Consequently, if $\vv{k}$ is feasible for $\ip$, then the constraint $\collapse{A}\vv{k} <\collapse{A} \tail{\vv{s}_q}$ and the above observations combine to tell us that \[ \norm{\vv{k}} \leq \iprod{\collapse{\vv{a}}}{\collapse{A} \vv{k}} < \iprod{\collapse{\vv{a}}}{\collapse{A} \tail{\vv{s}_q}} = \norm{\tail{\vv{s}_q}}\] 
which demonstrates that $\val \ip < \norm{\tail{\vv{s}}_q}$.  Finally, the positivity of $\collapse{A}\tail{\vv{s}}_q$ described in \Cref{tail projection: L} implies that $\vv{0}$ is feasible for $\ip$.
\end{proof}

\emily[inline]{Let's try to construct an example in which the optimal set of $\ip$ is infinite.}

\begin{corollary}
\label{finite image: C}
If $(A, \vv{u}, \vv{s}, q)$ is a list, then $\im \ip(A, \vv{u}, \vv{s}, q)$ is finite.
\end{corollary}

\begin{proof}  Adopt the notation from the proof of \Cref{bounded value: L}.

If $\vv{k}$ is optimal for $\ip$, then \eqref{bound in inner product: e} implies that \[ \val \ip = \norm{\vv{k}} \leq \iprod{\collapse{\vv{a}}}{\collapse{A} \vv{k}}\] and so $\collapse{A} \vv{k}$ is a lattice point in the polyhedron of all points $\vv{b}$  in $\rs(\O)^{\perp}$ with $\vv{b} < \collapse{A} \tail{\vv{s}_q}$  and $\iprod{\collapse{\vv{a}}}{\vv{b}} \geq \val \ip$.  The positivity of $\collapse{\vv{a}}$ in $\rs(\O)^{\perp}$ and \Cref{bounded polytope: L} then tell us  that this polyhedron is bounded.  
\end{proof}

\emily[inline]{Maybe we should make this a Theorem, and explain that this is a very important finiteness property. 
Potentially move it up before \Cref{bounded value: L}.}

\begin{lemma} 
\label{finitely many secondary programs: L} 
If $A$ is fixed, then there are only finitely many integer programs of the form $\ip(A, \vv{u}, \vv{s}, q)$ as we vary over all $A$-lists $(A, \vv{u}, \vv{s}, q)$.
\end{lemma}

\begin{proof}  Consider a list $(A, \vv{u}, \vv{s}, q)$.  As $A$ is fixed, there are only finitely many possibilities for $\O = \mf(A, \vv{u})$, and only finitely many possibilities for the set of supporting indices of any point $\vv{s} \in \mc_{\QQ}(A ,\vv{u})$.  

Next, let $\collapse{A}$ be the collapse of $A$ along the face $\O$.  If $\vv{s} \in \mc_{\QQ}(A, \vv{u})$, then $\vv{0} \leq \tail{\vv{s}}_q \leq \vv{1}$ for every integer $q > 0$, where $\vv{1}$ is the vector in the domain lattice of $A$ consisting of all ones.  Consequently, $\vv{0} \leq \collapse{A} \tail{\vv{s}}_q \leq \collapse{A}\, \vv{1}$, and as \Cref{tail projection: L} tells us that $\collapse{A} \tail{\vv{s}}_q$ has integer coordinates, it follows that there are only finitely many possibilities for this point.
\end{proof}

\begin{corollary} 
\label{finitely many coord sums: C}
 If $A$ is fixed, then there are only finitely many rational numbers of the form $ \norm{\tail{\vv{s}}_q}$ as we vary over all $A$-lists $(A, \vv{u}, \vv{s}, q)$.  
\end{corollary}

\begin{proof}  This follows from \eqref{norm of tail: e} and the proof of \Cref{finitely many secondary programs: L}.
\end{proof}


These finiteness properties above facilitate the following result.

\newcommand{\fsr}{\mathcal{R}}

\begin{theorem}[Existence of finite sets of representatives]  
\label{fsr-exist: T}
Given a monomial matrix $A$, there exists a finite subset $\fsr(A)$ of the domain lattice of $A$ with the following property\textup:  For every list $(A, \vv{u}, \vv{s}, q)$, and for every point $\vv{v} \in \im \ip(A, \vv{u}, \vv{s}, q)$, there exists a point $\vv{h} \in \fsr(A)$ with $\vv{h} \in \opt \Theta(A, \vv{s}, \vv{u}, q)$ and $\collapse{ A \vv{h}} = \collapse{A} \vv{h} =  \vv{v}$, where $\collapse{\mathcal{X}}$ denotes the collapse of $\mathcal{X}$ along $\O = \mf(A, \vv{u})$.
\end{theorem}

\begin{proof}  \Cref{finite image: C} implies that for every list $(A, \vv{u}, \vv{s}, q)$,  there exists a \emph{finite} subset $\fsr(A, \vv{u}, \vv{s}, q)$ of $\opt (A, \vv{u}, \vv{s}, q)$ such that 
\[ \collapse{A}(\fsr(A, \vv{u}, \vv{s}, q))  = \ol{ A(\fsr(A, \vv{u}, \vv{s}, q)) } = \im \ip (A, \vv{u}, \vv{s}, q) \] 
and \Cref{finitely many secondary programs: L} then implies that these sets may be chosen in such a way so that $\fsr(A) = \cup \, \fsr(A, \vv{u}, \vv{s}, q)$ is finite, where the union is over all $A$-lists.
\end{proof}


\newpage
\section{Toward solving $\Pi$}
\label{solving: S}

Suppose that $(A, \vv{u})$ is a monomial pair and that $q$ is positive integer. The goal in this subsection is to demonstrate that the value and image of \[ \IP(A, \vv{u}q) \] vary with $q$ in a uniform way as $q \to \infty$.

\subsection{Relating the two integer programs}
\label{relating-programs: ss}




\daniel[inline]{This needs updating.  Will give it a shot soon}

\begin{corollary}  
\label{uniform value and image: C}
Given a monomial matrix $A$, there exists an integer $\beta$ satisfying the following condition\textup:  If $(A, \vv{u})$ is a pair with $\O = \mf(A, \vv{u})$, $\vv{s} \in \mc_{\QQ}(A, \vv{u})$ is a point with denominator $D$, and $q>\beta D$, then 
%
\[ \val \IP(A, \vv{u}q) = \ft{A}{\vv{u}} \cdot q - \norm{\tail{\vv{s}}_q} + \val \ip(A, \vv{u}, \vv{s}, q) \] 
%
and 
\[ \ol{\im \IP(A, \vv{u}q)} = \collapse{\vv{u}} q - \collapse{A} \tail{\vv{s}}_q + \im \ip(A, \vv{u}, \vv{s}, q) \] 
where $\collapse{A}$ \textup(respectively, $\collapse{X}$\textup) is the collapse of $A$  \textup(respectively, $X$\textup) along $\O$.
\end{corollary}

\begin{proof}
Let $\beta$ be as in \Cref{uniform value: P}.  Fix a pair $(A, \vv{u})$ with $\O = \mf(A, \vv{u})$, a point $\vv{s} \in \mc_{\QQ}(A, \vv{u})$ with denominator $D$, and an integer $q > \beta D$.  Let $\collapse{A}$ and $\collapse{X}$ be as above.

The asserted value of $\IP(A, \vv{u}q)$ follows from \Cref{uniform value: P}.  Next, fix a point $\vv{k} \in \opt \IP(A, \vv{u}q)$, and let $\vv{h}$ be the unique lattice point such that $\vv{k} = \vv{s}q - \tail{\vv{s}}_q + \vv{h}$.  \Cref{comparison: R} implies that $\vv{h}$ is feasible for $\ip = \ip(A, \vv{u}, \vv{s}, q)$, while the optimality of $\vv{k}$ tells us that $\norm{\vv{k}} = \val \IP(A, \vv{u}q)$.  Keeping in mind our formula for $\val \IP(A, \vv{u}q)$, this equality tells us $\norm{\vv{h}} = \val \ip$.    Therefore, $\vv{h}$ must be optimal for $\ip$,  and so $\collapse{A} \vv{h} \in \im \ip$.  Furthermore, as $\collapse{A} \vv{s} = \collapse{\vv{u}}$, 

\[ \collapse{A} \vv{k} = \collapse{\vv{u}} q - \collapse{A} \tail{\vv{s}}_q + \collapse{A} \vv{h}\]  
which shows that $\collapse{A} ( \opt \IP(A, \vv{u}q))$ = $\ol{\im \IP(A, \vv{u}q)}$ is contained in 
\[ \collapse{\vv{u}} q - \collapse{A} \tail{\vv{s}}_q + \im \ip.\]

We now establish the opposite containment:  \Cref{uniform value: P} tells us that \[  \vv{s}q - \tail{\vv{s}}_q + \orep(A, \vv{u}, \vv{s}, q)\] is optimal for $\IP(A, \vv{u}q)$,  while \[ \collapse{A}( \orep(A, \vv{u}, \vv{s}, q)) = \im \ip \] by \Cref{orep: D}.   It follows that $\collapse{A}(\opt \IP(A, \vv{u}q)) = \ol{\im(A, \vv{u}q)}$ contains the set $\collapse{\vv{u}} q - \collapse{A} \tail{\vv{s}}_q + \im \ip$.
\end{proof}

\subsection{Some useful invariants}
\label{useful-invariants: ss}

In this subsection, we study the quantities appearing in \Cref{uniform value and image: C} above.  We begin with a fundamental observation.

\emily[inline]{Can we give a direct proof that $\delta$ does not depend on $\vv{s}$?}

\begin{corollary}  
\label{independence: C} Fix a pair $(A, \vv{u})$ and an integer $q>0$.  If $\collapse{A}$ is the collapse of $A$ along $\O = \mf(A, \vv{u})$, then the quantities
\[   \delta(A, \vv{u}, \vv{s}, q)  = \norm{\tail{\vv{s}}_q}  - \val \ip(A, \vv{u}, \vv{s}, q)\] and 
\[ \Delta(A, \vv{u}, \vv{s}, q)  = \collapse{A} \tail{\vv{s}}_q - \im  \ip( A, \vv{u}, \vv{s}, q)  \] 
do not depend on  $\vv{s} \in \mc_{\QQ}(A, \vv{u})$.  
\end{corollary}

\begin{proof}
Fix $\vv{s}$ and $\vv{s}'$ in $\mc_{\QQ}(A, \vv{u})$, as well as a common denominator $\denom$ for these points.  As these quantities clearly depend only on $q \bmod \denom$, it suffices to show that $\delta(A, \vv{u}, \vv{s}, q) = \delta(A, \vv{u}, \vv{s}', q)$  and $ \Delta(A, \vv{u}, \vv{s}, q) = \Delta(A, \vv{u}, \vv{s}', q)$ whenever $q \gg 0$.  However, this is follows from \Cref{uniform value and image: C}.
\end{proof}

\begin{definition}  
\label{independence: D}  

Given a pair $(A, \vv{u})$ and positive integer $q$, we set 
 \[ \delta(A, \vv{u}, q) = \norm{\tail{\vv{s}}_q}  - \val \ip(A, \vv{u}, \vv{s}, q)\] and 
\[\Delta(A, \vv{u}, q) = \collapse{A} \tail{\vv{s}}_q - \im  \ip( A, \vv{u}, \vv{s}, q)  \]
where  $\vv{s} \in \mc_{\QQ}(A, \vv{u})$, and $\collapse{A}$ is the collapse of $A$ along $\O = \mf(A, \vv{u})$. 
\end{definition}

%\begin{remark} Above, we referred to \Cref{uniform value and image: C} to deduce the independence of $\delta(A, \vv{u}, q)$ and $\Delta(A, \vv{u}, q)$ on the rational point $\vv{s} \in \mc_{\QQ}(A, \vv{u})$.  Though it seems likely that this can be established with a more direct argument, we have yet to identify one. 
%\end{remark}

\begin{lemma}  
\label{independence: L}  
If $\collapse{A}$ is the collapse of $A$ along $\O = \mf(A, \vv{u})$ and $q>0$ is an integer, then the following hold.

\begin{enumerate}
\item $\delta(A, \vv{u}, q)$  is a positive rational number.
\item $\Delta(A, \vv{u}, q)$ is a finite set of positive lattice points in $\rs(\O)^{\perp}$.
\item No column of $\collapse{A}$ is less than any point in $\Delta(A, \vv{u}, q)$.
\end{enumerate}
\end{lemma}

\begin{proof} 
Fix a point $\vv{s} \in \mc_{\QQ}(A, \vv{u})$ with which to compute $\delta = \delta(A, \vv{u}, q)$ and $\Delta = \Delta(A, \vv{u}, q)$.  \Cref{bounded value: L} implies that $\delta$ is positive, and \Cref{finite image: C} that $\Delta$ is a finite subset of $\ZZ \rb(\O)^{\perp}$.   The positivity of $\Delta$ in this lattice is a consequence of the constraints of $\ip = \ip(A, \vv{u}, \vv{s}, q)$.  These constraints also imply that no column of $\collapse{A}$ is less than any point in $\Delta$.  Indeed, if $\vv{k}$ is optimal for $\ip$, then optimality implies that  $\collapse{A}( \vv{k} + \vv{e}_i) \not < \collapse{A} \tail{\vv{s}}_q$ for each standard basis vector $\vv{e}_i$ in the domain of $\collapse{A}$, which we rewrite as  \[ \collapse{A} \vv{e}_i \not < \collapse{A} \tail{\vv{s}}_q - \collapse{A} \vv{k}.\] 
We conclude that no column of $\collapse{A}$ is less than $\collapse{A}\tail{\vv{s}}_q - \collapse{A}\vv{k}$.
\end{proof}

We conclude with some finiteness properties.


\emily[inline]{Maybe we should restate \Cref{finitely many deltas for a fixed A: P} more precisely. }


\begin{proposition}
\label{finitely many deltas for a fixed A: P}
 Given a monomial matrix $A$, there are only finitely many objects of the form $\delta(A, \vv{u}, q)$ and $\Delta(A, \vv{u}, q)$.
\end{proposition}

\begin{proof}
This follows immediately from \Cref{finitely many secondary programs: L} and \Cref{finitely many coord sums: C}.
\end{proof}

\begin{remark}  
\label{comparing deltas: R}
If $(\collapse{A}, \collapse{\vv{u}})$ is the collapse of $(A, \vv{u})$ along $\O = \mf(A, \vv{u})$, then  
\[ \delta(A, \vv{u}, q) = \delta(\collapse{A}, \collapse{\vv{u}}, q)  \text{ and }  \Delta(A, \vv{u},q) = \Delta(\collapse{A}, \collapse{\vv{u}}, q)\] for all integers $q>0$ (e.g., this follows from \Cref{collapsed aux program: R}).   Consequently, one may replace the point in $\mc_{\QQ}(A, \vv{u})$ in \Cref{independence: D}   with one in $\mc_{\QQ}(\collapse{A}, \collapse{\vv{u}})$ without affecting the value of $\delta(A, \vv{u}, q)$ and $\Delta(A, \vv{u}, q)$.
\end{remark}

\begin{remark}
\label{pair periodicity: R}
If $(A, \vv{u})$ is fixed, then $\delta(A, \vv{u}, q)$ and $\Delta(A, \vv{u}, q)$ are periodic in $q$.  Indeed, if $\denom$ is the denominator of some point in $\mc_{\QQ}(A, \vv{u})$, then 
\begin{equation}
\label{periodicity: e}
 \delta(A, \vv{u}, p) = \delta(A, \vv{u}, q)  \text{ and } \Delta(A, \vv{u}, p) = \Delta(A, \vv{u}, q)
\end{equation} whenever $p \equiv q \bmod \denom$.    In fact, \Cref{comparing deltas: R} tells us that the same is true if instead $\denom$ is the denominator of a point in $\mc_{\QQ}(\collapse{A}, \collapse{\vv{u}})$.
\end{remark}

\begin{remark}
\label{uniform periodicity: R}
 If only $A$ is specified, then there exists a uniform integer $\denom$ such that \eqref{periodicity: e} holds for every pair $(A, \vv{u})$ whenever $p \equiv q \bmod \denom$.  
 
 Indeed,  this follows from the observation that if $\denom$ is as in \Cref{uniform denominators for mc:  T}, then we may compute  $\delta(A, \vv{u}, q)$ and $\Delta(A, \vv{u}, q)$ for all pairs $(A, \vv{u})$ and integers $q>0$ in terms of a point in $\mc_{\QQ}(A, \vv{u})$ with denominator $\denom$.
\end{remark}

We record another application of \Cref{uniform denominators for mc:  T} below.

\begin{theorem}
\label{uniform uniform value and image: T}
Given a monomial matrix $A$, there exists a integer $\beta$ with the following property\textup:  If $q > \beta$ and $(A, \vv{u})$ is a pair, then \[ \val \IP(A, \vv{u}q) = \ft{A}{\vv{u}} \cdot q - \delta(A, \vv{u}, q) \] and
\[ \ol{ \im \IP(A, \vv{u}q)} = \collapse{\vv{u}}q - \Delta(A, \vv{u},q) \] where $\collapse{X}$ denotes the collapse of a subset $X$ along $\O = \mf(A, \vv{u})$.
\end{theorem}

\begin{proof}  
\Cref{uniform denominators for mc:  T}  tells us that once $A$ has been fixed, there exists a positive integer $D$ such that for every pair $(A, \vv{u})$, there exists a point in $\mc_{\QQ}(A, \vv{u})$ with denominator $D$.  Therefore, if $\beta_{\circ}$  is any integer satisfying the condition stated in \Cref{uniform value and image: C}, then we may take $\beta = D \beta_{\circ}$.  
\end{proof}

The following is a consequence of \Cref{comparing deltas: R} and \Cref{uniform uniform value and image: T}.

\begin{corollary}
Given a monomial matrix $A$, there exists an integer $\beta$ with the following property\textup:  If $q > \beta$ and $(A, \vv{u})$ is a pair with $\O = \mf(A, \vv{u})$, then $\val \IP(A, \vv{u}q) = \val \IP(\collapse{A}, \collapse{\vv{u}}q)$ and $\ol{ \im(A, \vv{u}q)} = \im(\collapse{A}, \collapse{\vv{u}}q)$ where $\collapse{A}$ \textup(respectively, $\collapse{X}$\textup) is the collapse of $A$  \textup(respectively, $X$\textup) along $\O$.
\end{corollary}

\emily[inline]{The following could just replace the above statement?  Replace integer programming language with algebraic language? For instance, as follows?}

\begin{corollary}
For $p \gg 0$, 
 $\nu(A, \vv{u}, q) = \nu(\collapse{A}, \collapse{\vv{u}}, q)$. 
\end{corollary}


\newpage




\newpage


\section{Arithmetic integer programming}


\emily[inline]{Motivate this via $\mu$s.}

In this section, we consider a variant of an integer program in which we impose an additional, and {highly} nonlinear, constraint.  As this new constraint is arithmetic in nature, we call such an optimization problem an \emph{arithmetic integer program}, and we will focus exclusively on one such family of optimization problems.  We define the terms \emph{feasible, optimal}, and \emph{value} relative to an arithmetic program in the analogous way.   

In what follows, $(A, \vv{u})$ is a $d \times n$ monomial pair.


\begin{definition} If $p>0$ is a prime integer, then $\IP_p(A, \vv{u})$ is the arithmetic integer program in $\ZZ^n$ defined as follows:
\begin{enumerate}
\item The linear constraints are $\vv{k} \geq \vv{0}$ and $A \vv{k} < \vv{u}$.  
\item The nonlinear (arithmetic) constraint is that $\binom{\norm{\vv{k}}}{\vv{k}} \not \equiv 0 \bmod p$.
By Dickson's Theorem \cite{dickson.multinomial}, this is equivalent to the condition that  if \[ \vv{k} = \vv{k}_0 + \cdots + \vv{k}_l \cdot  p^l\] is the unique terminating base $p$ expansion of $\vv{k}$, then $\norm{\vv{k}_e} < p$ for all $0 \leq e \leq l $.
\item The objective function is $\vv{k} \mapsto \norm{\vv{k}}$.
\end{enumerate}

\end{definition}


\daniel[inline]{It is possible that we don't use the image of this program anywhere.  Maybe only the image of $\ip$.}

\begin{definition}
The \emph{image} of $\IP_p(A, \vv{u})$ is the set $\im \IP_p(A, \vv{u})$ of all points  $A \vv{k}$ with $\vv{k} \in \opt \IP_p(A, \vv{u})$. 
\end{definition}

We seek to understand of the behavior of the arithmetic program \[ \IP_p(A, \vv{u}p^e)\] for all $p \gg 0$ and $e \geq 1$.    As will soon be apparent, these programs are more subtle than their non-arithmetic analogs.  We gather some basic general results pertaining to these programs below;  more specialized arguments will appear in the next section.

\begin{lemma} 
\label{optimal division: L}  If $(A, \vv{u})$ is a monomial pair, then the quotient when dividing any optimal point of $\IP_p(A, \vv{u}p^e)$ by $p^e$ must be optimal for $\IP_p(A, \vv{u})$.
\end{lemma}

\begin{proof}  Suppose $\vv{g} \in \opt \IP_p(A, \vv{u}p^e)$ and write 
\[ \vv{g} = \vv{h} p^e + \vv{k} \]
with $\vv{h}$ and $\vv{k}$ in $\NN^d$ such that every coordinate of $\vv{k}$ is less than $p^e$.

The arithmetic constraint satisfied by $\vv{g}$ implies that both $\binom{\norm{\vv{h}}}{\vv{h}}$ and $\binom{\norm{\vv{k}}}{\vv{k}}$ are nonzero mod $p$.  By construction,  the base $p$ expansion of $\vv{k}$ is of the form $\vv{k} = \vv{k}_0 + \cdots + \vv{k}_{e-1} \cdot p^{e-1}$, and so the arithmetic constraint satisfied by $\vv{k}$ implies that $\norm{\vv{k}} < p^e$.   Consequently, if $\vv{h}$ were not optimal for $\IP_p(A, \vv{u})$, then there would exist $\vv{m} \in \IP_p(A, \vv{u})$ with $\norm{\vv{m}} \geq \norm{\vv{h}} + 1$, which would lead to a point $\vv{m}p^e \in \IP_p(A, \vv{u}p^e)$ whose norm is \[ \norm{\vv{m}}p^e \geq \norm{\vv{h}} \cdot p^e + p^e >  \norm{\vv{h}} \cdot p^e + \norm{\vv{k}} = \norm{\vv{g}}\] which contradicts the optimality of $\vv{g}$. % We conclude that $\vv{h} \in \opt \IP_p(A, \vv{u})$.
\end{proof}

We record some corollaries of \Cref{optimal division: L} below.

\daniel[inline]{Should we just think about \Cref{natural bounds: C} algebraically?}

\begin{corollary} 
\label{natural bounds: C}
If $(A, \vv{u})$ is a monomial pair and $e \geq 1$, then 
\[ \val \IP_p(A, \vv{u}) \cdot p^e \leq \val \IP_p(A, \vv{u}p^e) < (\val \IP_p(A, \vv{u}) +1) \cdot p^e. \]
\end{corollary}
\begin{proof}
These bounds follow from a direct computation of the norm of the optimal point $\vv{g}$ in the proof of \Cref{optimal division: L}
\end{proof}

\begin{corollary}\label{cor: mu comparison}  If $(A, \vv{u})$ and $(B, \vv{v})$ are monomial pairs such that \[ \val \IP_p(A, \vv{u}) > \val \IP_p(B, \vv{v})\] then $\val \IP_p(A, \vv{u}p^e) > \val \IP_p(B, \vv{v}p^e)$ for all $e \geq 0$.
\end{corollary}

\begin{proof}   If $\val \IP_p(A, \vv{u}) \geq \val \IP_p(B, \vv{v}) + 1$, then \Cref{natural bounds: C} tells us that 
$\val \IP_p(A, \vv{u}p^e)  \geq \IP_p(A, \vv{u}) \cdot p^e   \geq (\IP_p(B, \vv{v})+1)\cdot p^e > \val \IP_p(B, \vv{u}p^e)$.
\end{proof}

\subsection{Small pairs}

\ \pedro[inline]{Postpone introduction of medium small points until immediately before definition of $\widehat{\graph}$ graph?}

\begin{definition}
A monomial pair $(A, \vv{u})$ is \emph{small} $\vv{u}$ is not greater than any column of $A$, and is \emph{very small} if $\ft{A}{\vv{u}}$ is at most one.
\end{definition}

\begin{remark}
\label{finitely many small but not very small: R}
Geometrically, $(A, \vv{u})$ is small if and only if $\vv{u}$ does not lie in the interior of the upper staircase associated to the columns of $A$, and very small if $\vv{u}$ does not lie in the interior of the Newton polyhedron of $A$.  

It is clear from this geometric interpretation that ``very small'' implies ``small.''  Furthermore, once $A$ is fixed, there are only finitely pairs $(A, \vv{u})$ that are small, but not very small. \daniel{Do we need a proof?}
\end{remark}

\begin{lemma}
\label{refined-discreteness: L}
Given a monomial matrix $A$, there exists $\delta = \delta(A)$ such that $\ft{A}{\vv{u}} < \delta$ whenever $(A, \vv{u})$ is small.
\end{lemma}

\begin{proof}   Fix a small pair $(A, \vv{u})$ with $\O = \mf(A, \vv{u})$.  If $\epsilon$ is the number of columns of $A$ lying on $\O$, then it suffices to prove that $\ft{A}{\vv{u}} \leq \epsilon$.

By means of contradiction, suppose that $\ft{A}{\vv{u}} > \epsilon$.  If $\vv{s} \in \mc(A,\vv{u})$, then $\norm{\vv{s}} = \ft{A}{\vv{u}} > \epsilon$, and as $\vv{s}$ has at most $\epsilon$ nonzero entries, some entry of $\vv{s}$ must be greater than $1$.  Thus, $A \vv{s}$ is greater than some column of $A$.  However, our choice of $\vv{s}$ also implies that $A \vv{s} \leq \vv{u}$, which then implies that $\vv{u}$ is greater than some column of $A$, contradicting the smallness of $(A, \vv{u})$.
\end{proof}

\begin{lemma}
\label{trivial value bound: L}
If $(A, \vv{u})$ is small, then 
 \[ \val \IP_p(A, \vv{u}p^e) \leq p^{e} -1 \] for every $p > 0$ and $e \geq 0$.
\end{lemma}


\begin{proof}
Note that $(A, \vv{u})$ is small if and only if only $\vv{0}$ is feasible for $\IP(A, \vv{u})$.   Thus, $\val \IP(A, \vv{u}) = 0$, and the assertion then follows from \Cref{natural bounds: C}.
\end{proof}

%\begin{proof} If $\vv{k}$ is feasible for $\IP_p(A, \vv{u}p^e)$ and $ p^e \vv{e}_i  \leq \vv{k}$ for some standard basis vector $\vv{e}_i$ of $\ZZ^n$, then $p^e A \vv{e}_i  \leq A \vv{k} < \vv{u}p^e$, and therefore $A \vv{e}_i < \vv{u}$, which contradicts the smallness of $(A, \vv{u})$.  Thus, every coordinate of $\vv{k}$ is less than $p^e$, and so the base $p$ expansion of $\vv{k}$ is of the form $\vv{k} = \vv{k}_0 + \cdots + \vv{k}_{e-1} p^{e-1}$.  The arithmetic constraint of the program then implies that $\norm{\vv{k}} \leq p^e-1$.
%\end{proof}

% \emily[inline]{If 
% \[
%  \ideala^{\left[ \mu_\ideala^{\vv{u}}(q) \right] } \equiv \langle x^{\vv{u}q - \vv{z}} \mid \vv{z} \in \Z \subseteq \NN_+^d \rangle \bmod \operatorname{diag}(\vv{u}q)\]
%  then 
%  \[
% \operatorname{crit}(\ideala, \vv{u}) = \frac{1}{q}\left( \mu^{\vv{u}}_\ideala(q) + \max \{ \operatorname{crit}(\ideala, \vv{z}) \mid \vv{z} \in \Z \}  \} \right)
% \]
% }


\begin{proposition}
\label{follow-leftovers: P}
Suppose $(A, \vv{u})$ is a monomial pair.  If \[ \im \IP(A, \vv{u}) = \vv{u} - \Z\] then every pair $(A, \vv{z})$ with $\vv{z} \in \Z$ is small, and if $p \gg 0$ and $e \geq 0$, then 
\[ \val \IP_p(A, \vv{u} p^e) = \val \IP(A, \vv{u}) \cdot p^e + \max \val \IP_p(A, \vv{z}p^e) \]
where the maximum is over all points $\vv{z} \in \Z$.
\end{proposition}

\daniel[inline]{This proof seems way to long.  Might be shortened if we think about things algebraically}

\begin{proof}  The constraints of $\IP(A, \vv{u})$ imply that $\Z$ is a finite set of lattice points with positive coordinates.   These constraints and optimality also imply that if $\vv{e}$ is a standard basis vector in the domain of $A$, then no point in the Minkowski sum $\vv{e} + \opt \IP(A, \vv{u})$ can be feasible for $\IP(A, \vv{u})$.  Applying $A$ to this shows that no point in 
\[ A \vv{e} + \im \IP(A, \vv{u}) = A \vv{e} + \vv{u} - \Z \] 
is less than $\vv{u}$.  Thus, $A \vv{e}$ is not less than any point in $\Z$, and as $\vv{e}$ was arbitrary, it follows that $(A, \vv{z})$ is small for every $\vv{z} \in \Z$.

The finiteness of $\Z$ allows us to choose $p$ large enough so that \[ \val \IP(A, \vv{v}) \leq p -1 \] for every point $\vv{v} \in \Z \cup \{ \vv{u} \}$.  In this case, every feasible point for $\IP(A, \vv{v})$  automatically satisfies the arithmetic constraint of $\IP_p(A, \vv{v})$, which allows us to conclude that $\IP(A, \vv{v}) = \IP_p(A, \vv{v})$.  In particular, \[ \im \IP_p(A, \vv{u}) =\vv{u} - \Z. \] 

Next, fix $\vv{g}$ optimal for $\IP_p(A, \vv{u}p^e)$.  If $\vv{h}$ is the quotient, and $\vv{k}$ the remainder, when dividing $\vv{g}$ by $p^e$, then \Cref{optimal division: L} tells us that $\vv{h}$ is optimal for $\IP_p(A, \vv{u})$, so that $A \vv{h} = \vv{u}-\vv{z}$ for some $\vv{z} \in \Z$.  The feasibility of $\vv{g}=\vv{h}p^e + \vv{k}$ for $\IP_p(A, \vv{u}p^e)$ then implies the feasibility of $\vv{k}$ for $\IP_p(A, \vv{z}p^e)$.  This establishes that $\norm{\vv{g}} = \val \IP_p(A, \vv{u}p^e)$ is at most the asserted value.

To establish the opposite inequality, suppose $\vv{z}^{\ast}$ is a point in $\Z$ with $\val \IP_p(A, \vv{z}^{\ast} p^e)$ maximal.  By virtue of being in $\Z$, we may write $\vv{z}^{\ast} = \vv{u} - A \vv{g}^{\ast}$ for some $\vv{g}^{\ast} \in \opt \IP(A, \vv{u})$.  If $\vv{k}^{\ast}$ is optimal for $\IP_p(A, \vv{z}^{\ast} p^e)$, then a direct computation will show that 
$\vv{h}^{\ast} = \vv{g}^{\ast} \cdot p^e + \vv{k}^{\ast}$ satisfies the linear constraint of  $\IP_p(A, \vv{u}p^e)$.  Furthermore, the feasibility of $\vv{k}^{\ast}$ implies that $\binom{\norm{\vv{k}^{\ast}}}{\vv{k}^{\ast}} \not \equiv 0 \bmod p$, and the smallness of $(A, \vv{z}^{\ast})$ and \Cref{trivial value bound: L} tell us that $\norm{\vv{k}^{\ast}} \leq p^e-1$.  On the other hand, our choice of $p \gg 0$ tells us that $\norm{\vv{g}^{\ast}} = \val \IP_p(A, \vv{u}) = \val \IP(A, \vv{u}) \leq p-1$, and it follows that $\vv{h}^{\ast}$ also satisfies that the arithmetic constraint of $\IP_p(A, \vv{u}p^e)$.
\end{proof}


We have just shown that to compute the value of $\IP_p(A, \vv{u}p^e)$ for all $p \gg 0$ and $e \geq 1$, we may assume that $(A, \vv{u})$ is small.  Below, consider an important special case of this simplified situation.

\daniel[inline]{\Cref{trivial max value: T} looks like it could follow from ILL and then just modifying the $\vv{k}'s$ immediately.  But, the following is more direct.}

\begin{theorem}
\label{trivial max value: T}  Given a monomial matrix $A$, there exists an integer $\beta$ with the following property\textup:   
If $(A, \vv{u})$ is small, but not very small, then  \[ \val \IP_p(A, \vv{u}p^e) = p^e-1\] for every $p > \beta$ and $e \geq 1$.
\comment{Compare Theorem~6.4 of \emph{Frobenius Powers}}
\end{theorem}

\begin{proof} Suppose that $(A, \vv{u})$ is small, but not very small, and fix $\vv{s} \in \mc_{\QQ}(A, \vv{u})$, so that $\norm{\vv{s}} = \ft{A}{\vv{u}} > 1$.   
Set  $\vv{t} = \vv{s} / \norm{\vv{s}}$ and note that $\vv{0} \leq \vv{t} \leq \vv{s}$, with the latter inequality strict in every coordinate in which $\vv{s}$ is positive.  

Next, fix an index $i$ such that the $i$-th coordinate of $\vv{s}$ is positive.  As $\tail{\vv{t}}_p$ obtains only finitely many values as $p$ varies, our choice of $i$ guarantees that 
\[ 0 \leq \vv{t} - \frac{\tail{\vv{t}}_p}{p} + \frac{\norm{\tail{\vv{t}}_p}}{p} \cdot \vv{e}_i  \leq \vv{s} \]
for all $p \gg 0$, with the latter inequality strict in every coordinate in which $\vv{s}$ is positive.  For such $p \gg 0$,  \Cref{less than u: L} tells us that 
%
 \[ A \left(  \vv{t}p - \tail{\vv{t}}_p + \norm{\tail{\vv{t}}_p} \cdot \vv{e}_i  \right) < \vv{u}p. \]
%
 
 By construction, $\norm{\vv{t}} = 1$, and as $\vv{t}p - \tail{\vv{t}}_p$ has nonnegative integer coordinates, we have that $\norm{\tail{\vv{t}}_p}$ is also a positive integer.  In summary, 
  \[ \vv{k}_p  =   \vv{t}p - \tail{\vv{t}}_p+ (\norm{\vv{t}}_p - 1) \cdot \vv{e}_i   \] has nonnegative integer coordinates and satisfies $A \vv{k}_p < \vv{u}p - A \vv{e}_i$.  A direct calculation will also show that $\norm{\vv{k}_p} = p-1$. 
  
 Given this, it is straightforward to verify that the point
 \[ \vv{k}_p \cdot p^{e-1} + (p^{e-1} - 1) \cdot \vv{e}_i \]
 has norm $p^e-1$ and is feasible for $\IP_p(A, \vv{u}p^e)$ for all $e \geq 1$.  \Cref{trivial value bound: L} then allows us to conclude that $\val \IP_p(A, \vv{u}p^e)  = p^e-1$ for all $e \geq 1$.
 
To conclude the proof, it suffices to recall that, as noted in \Cref{finitely many small but not very small: R},  there are only finitely many $(A, \vv{u})$ that are small, but not very small.
\end{proof}


\comment[inline]{At this point, it suffices to deal with the case that $(A, \vv{u})$ is very small}

\daniel[inline]{Should we state this more algebraically?}

\begin{theorem}
\label{arithmetic uniform value and image: T}   Given a monomial matrix $A$, there exists an integer $\beta$ with the following property\textup:  
If $(A, \vv{u})$ is a very small and $p > \beta$, then  \[ \val \IP_p(A, \vv{u}p) = \ft{A}{\vv{u}} \cdot p - \delta(A, \vv{u}, p). \] 
and 
\[ \ol{ \im \IP_p(A, \vv{u} p)} = \collapse{\vv{u}}p - \Delta(A, \vv{u}, p) \] where $\collapse{X}$ denotes the collapse of a subset $X$ of $\RR^d$ along $\O = \mf(A, \vv{u})$.
\end{theorem}

\begin{proof}  If $\beta$ is as in \Cref{uniform uniform value and image: T}, then \[ \val \IP(A, \vv{u}p) = \ft{A}{\vv{u}} \cdot p - \delta(A, \vv{u}, p) \] for every pair $(A, \vv{u})$ and $p > \beta$.  If this pair is very small, so that $\ft{A}{\vv{u}} \leq 1$, the positivity of $\delta(A, \vv{u},p)$ will then imply that this quantity is less than $p$.  Consequently, every $\vv{k}$ feasible for $\IP(A, \vv{u}p)$ satisfies $\norm{\vv{k}} \leq p-1$, and therefore satisfies the arithmetic constraint of $\IP_p(A, \vv{u}p)$.  We conclude that $\IP(A, \vv{u}p) = \IP_p(A, \vv{u}p)$ whenever $(A, \vv{u})$ is very small and $p > \beta$.
\end{proof}

\emily[inline]{If $(A, \vv{u})$ is small but not very small, then $\mu_\ideala^{\vv{u}}(p) = p-1$, so $\mu_\ideala^{\vv{u}}(p) \neq \nu_\ideala^{\vv{u}}(p)$.
In this case, although our description of $\ideala^{\nu_\ideala^{\vv{u}}(p)}$ does not depend on $p$, we \emph{can} have that the generators of $\ideala^{\mu_\ideala^{\vv{u}}(p)}
= \ideala^{p-1}$ depend on $p$:  For instance, if $\ideala = \langle x, y, \rangle$, then $\nu_\ideala^{\vv{u}}(p) = 2p-2$  and $\mu_\ideala^{\vv{u}}(p) = p-1$.  Moreover, $x^{p-(p+1)/2}y^{p-(p+1)/2} \in \ideala^{p-1}$.
(Actually, all minimal generators of $\ideala^{p-1}$ depend on $p$.)
}




\newpage


\section{A graph}

\todo[inline]{Set notation for sprouts/set of sprouts/sprouts of sets.}


\daniel[inline]{Perhaps we should motivate why we would want to look at $p$-sprouts.  The point is that they determine which $\mu$'s we should compute next, at least in terms of the collapse.}


\subsection{Sprouting}

\begin{definition}
\label{p-sprout: D}
We say that $(B, \vv{v})$ is a \emph{$p$-sprout} of a monomial pair $(A, \vv{u})$ whenever the following conditions are satisfied.
\begin{enumerate}
\item $B$ is the collapse of $A$ along the minimal face $\O = \mf(A, \vv{u})$.
\item $\vv{v}$ is any point in $\Delta(A, \vv{u}, p)$.
\end{enumerate}
\end{definition}



\begin{remark}
\label{p-sprout: R} 
As noted in \Cref{collapse of monomial is monomial: R}, the collapse of a monomial matrix along a face of its Newton polyhedron is monomial, and so a $p$-sprout of a monomial pair is also a monomial pair.  Furthermore,   \Cref{independence: L} tells us that there are only finitely many $p$-sprouts of a fixed monomial pair, and that each such sprouted pair is small. 
 \end{remark}

The following statement may be regarded as a refinement of the upper bound given in \Cref{natural bounds: C}, at least when $p$ is large enough.

\emily[inline]{It seems like we prove that $\mu(A, \vv{u}, q) = \mu(\collapse{A}, \collapse{\vv{u}}, q)$.  Let's make sure to state that later.
}

\begin{corollary}\label{cor: upper bound for higher mus}
Given a monomial matrix $A$, there exists an integer $\beta$ with the following property\textup:  If $(A, \vv{u})$ is very small, then
%
\[ \val \IP_p(A, \vv{u}p^{e+1})  \leq  \val \IP_p(A, \vv{u}p) \cdot p^e +  \max \val \IP_p(B, \vv{v}p^e) \] 
%
for all $p > \beta$ and $e \geq 1$, where the maximum is over all $p$-sprouts $(B, \vv{v})$ of $(A, \vv{u})$.  
\end{corollary}

\begin{proof}  Let $\beta$ be as in \Cref{arithmetic uniform value and image: T}, and fix a pair $(A, \vv{u})$ that is very small.
Suppose $\vv{g}$ is optimal for $\IP_p(A, \vv{u}p^{e+1})$, and let $\vv{h}$ and $\vv{k}$ be the quotient and remainder, respectively, when dividing $\vv{g}$ by $p^e$.

Let $\collapse{X}$ be the collapse of a subset $X$ of $\RR^d$ along $\O = \mf(A, \vv{u})$.  \Cref{optimal division: L} tells us that $\vv{h}$ must be optimal for $\IP_p(A, \vv{u}p)$, and \Cref{arithmetic uniform value and image: T} then implies that $B \vv{h} = \collapse{A \vv{h}} \in \ol{\im \IP_p(A, \vv{u}p)} = \collapse{\vv{u}}p - \Delta(A, \vv{u}, p)$ for all $p > \beta$.   
Therefore, for $p > \beta$, we may write \[ B \vv{h} = \collapse{\vv{u}}p - \vv{v}\] for some $\vv{v} \in \Delta(A, \vv{u}, p)$.  On the other hand, our choice of $\vv{g}$ guarantees that $A \vv{g} < \vv{u}p^{e+1}$, which leads to the inequality $B \vv{h} p^e + B \vv{k} = B \vv{g} <  \collapse{\vv{u}}p^{e+1}$  in $\rs(\O)^{\perp}$.  Comparing this with the above description of $B \vv{h}$ shows that \[ B \vv{k} < \vv{v} p^e \] which allows us to conclude that $\vv{k} \in \IP_p(B, \vv{v} p^e)$.  %The corollary then follows from the fact that $\norm{\vv{g}} = \norm{\vv{h}} \cdot p^e + \norm{\vv{k}}$.
\end{proof}


\subsection{The Sprouting graph}


\begin{definition} \daniel{By the way, I think Emily and I have shown that the collapse of a collapse of $A$ is a collapse of $A$.  This will mean that the only matrices that can appear in $\S_p(A)$ are the collapses of $A$.  We don't gain any stronger theoretical finiteness properties, but this might simplify any implementations}
Given a monomial matrix $A$ and a prime $p$, define
\begin{enumerate}
   \item $\graph^0(A,p) = \{(A,\vv{u}) : (A,\vv{u})\text{ is a small monomial pair} \}$;
   \item $\displaystyle\graph^{e+1}(A,p) = \bigcup_{(B,\vv{v})\in \graph^e(A,p)}\sprouts(B,\vv{v})$ for $e \geq 0$. 
\end{enumerate}
\end{definition}


\emily[inline]{We think that $\{ \graph^e : e \geq 1 \}$ is finite, but only care that $\bigcup_{e=1}^\infty \graph^e(A)$ is.}

\emily[inline]{verify that $\graph_e(A, \vv{u})$ and $\graph_e(A)$ are eventually periodic}
\daniel[inline]{In the remark (or wherever) when we gather some basic finiteness properties, at least state that there are only finitely many matrices appearing in any vertex of $\graph_p(A)$ as $p$ varies}

%\subsection*{Finiteness properties}
%
%Once $A$ is fixed,
%\begin{itemize}
% \item $\bigcup_{e=1}^\infty \graph^e(A,p)$ is finite.
% \item There exist $D$ such that for all $e \geq 1$ and $(B, \vv{v}) \in \graph^e(A,p)$, there exists $\vv{s} \in \mc(B, \vv{v})$ with denominator $D$. 
% \item $\mathbb{O}(A)$ is finite, and $\bigcup_{(B, \vv{v}) \in \graph^e(A), \text{ some } e} \mathbb{O}(B, \vv{v}, \vv{s}, p)$ is finite.
% \item Add the last point
%\end{itemize}

\newpage
\begin{theorem}[Iterated lifting]
\label{ILL: T}
   For each monomial matrix $A$, there exists an integer $\beta = \beta(A)$ with the following property\textup:
   If $p>\beta$ and $(A_1, \vv{u}_1) \to (A_2, \vv{u}_2) \to \cdots \to (A_e, \vv{u}_e)$ is a path in $\graph_p(A)$, then for every $1 \leq i \leq e$, there exists a point $\vv{k}_i \in \opt \Pi(A_i, \vv{u}_i,p)$  for which 
 \[
  \vv{k}_1 p^{e-1} + \vv{k}_2 p^{e-2} + \cdots + \vv{k}_{e-1} p + \vv{k}_e \in \feas \Pi(A_1, \vv{u}_1, p^e).
 \]
\end{theorem}

\begin{proof}\daniel{The ``finiteness properties" part of this proof is slightly different than what we sketched in Lawrence, but the rest of the argument follows what we talked about then.  I think it is correct, but it would be nice if someone could verify this.}  We start by describing what it means $p$ to be large.  Toward this, let $M_1, \cdots, M_l$\daniel{Update these $M_i$ if we include a proof that the collapse of a collapse of $A$ is a collapse of $A$.} be the finitely many monomial matrices obtained from $A$ by omitting some of its columns.  \Cref{special-denominators-exist:  T} allows us to fix a positive integer $\denom$ that is a special denominator for each such matrix.  We may also fix a finite set of representatives $\fsr(M_i)$ for each such matrix, as described in \Cref{fsr-exist: T}.  Set $\fsr = \fsr(M_1) \cup \cdots \cup \fsr(M_l)$, and let $\Omega$ be the set consisting of all coordinates of all points in $A(\fsr)$.  We stress that $\fsr$ and $\Omega$ are finite sets determined by $A$, and do not depend in any way on $p$.  

Consider the conditions \eqref{p-big-1} and \eqref{p-big-2} below.  
%
\begin{align}
\tag{$\heartsuit$} \label{p-big-1}
\text{$p/\denom$ is greater than any coordinate of any point in $\vv{1} - \fsr$.} \\ 
 \label{p-big-2}
\tag{$\diamondsuit$}\text{$p^e / \denom > \sum_{i=1}^e \omega_i \cdot p^{e-i}$ for every $e \geq 1$ and $\omega_1, \cdots, \omega_e \in \Omega$,}
\end{align}

The finiteness of $\fsr$,  and \Cref{positive-polynomial: L} below, imply that there exists an integer $\beta = \beta(\denom, \fsr)$ for which \eqref{p-big-1} and \eqref{p-big-2} hold whenever $p > \beta$.  In what follows, we assume that $p$ is chosen so that these conditions are satisfied.

Now, consider a finite path \[ (A_1, \vv{u}_1) \to (A_2, \vv{u}_2) \to \cdots \to (A_e, \vv{u}_e) \] in $\graph_p(A)$.  For every $1 \leq i \leq e$, set $\O_i = \mf(A, \vv{u}_i)$, and fix a special point $\vv{s}_i \in \mc(A_i, \vv{u}_i)$ with denominator $\denom$.  If $1 \leq i < e$, then the sprouting $(A_i, \vv{u}_i) \to (A_{i+1}, \vv{u}_{i+1})$ tells us that $A_{i+1}$ is the collapse of $A_i$ along $\O_i$, and that $\vv{u}_{i+1} \in \Delta(A_i, \vv{u}_i, q) = A_{i+1} \tail{\vv{s}_i}_p - \im  \ip( A_i, \vv{u}_i, \vv{s}_i, p)$.  Theorem \Cref{fsr-exist: T}, and our choice of $\fsr$, then allow us to fix a point $\vv{h}_i$ in $\fsr \cap \opt \ip ( A_i, \vv{u}_i, \vv{s}_i, p)$ such that 
$\vv{u}_{i+1} = A_{i+1} \tail{\vv{s}_i}_p - A_{i+1} \vv{h}_i$.  Finally, we take $\vv{h}_e$ to be an arbitrary point in the nonempty set $\fsr \cap \opt \ip ( A_e, \vv{u}_e, \vv{s}_e, p)$.


Next, for every $1 \leq i \leq e$,  we define
  \[
\vv{k}_i = \vv{s}_i \cdot p - [\vv{s}_i]_p + \vv{h}_i.
\]
Observe that \eqref{p-big-1} and \eqref{p-big-2} imply that for every $1 \leq i \leq e$, the quantity $p/\ell$ is greater than every coordinate of $\vv{1}-\vv{h}_i$, and every coordinate of $A_i \vv{h}_i$.  It then follows from \Cref{uniform value: P} (or rather, its proof) that 
\begin{equation}
\label{optimality-for-each-component: e}
\vv{k}_i \in \opt \Pi(A_i, \vv{u}_i,p)
\end{equation}
for every $1 \leq i \leq e$.

We will now induce on $e$ to prove that $\sum_{i=1}^e \vv{k}_i \cdot p^{e-i}$ is feasible for $\IP(A_1, \vv{u}_1, p^e)$.  When $e = 1$, this follows from \eqref{optimality-for-each-component: e}.  Next, suppose that $e \geq 2$.  Our induction hypothesis applied to the truncated path  
\[ (A_2, \vv{u}_2) \to \cdots \to (A_e, \vv{u}_e) \]
%
tells us that $\vv{k}^{\ast} = \sum_{i=2}^e \vv{k}_i \cdot p^{e-i} \in \feas \IP(A_2, \vv{u}_2, p^{e-1})$.  To complete the induction step, we must show that $\vv{k}_1 p^{e-1} + \vv{k}^{\ast}$ is feasible for $\IP(A_1, \vv{u}_1, p^e)$.  However,  \eqref{optimality-for-each-component: e} implies that this point has nonnegative integer coordinates, and hence, we must only show that $A_1 ( \vv{k}_1 p^{e-1} + \vv{k}^{\ast} ) < \vv{u}_1 p^e$.

To do so,  recall that our choice of $\vv{s}_1 \in \mc(A_1, \vv{u}_1)$ allows us to express $\vv{u}_1$ as 
$\vv{u}_1 = A_1 \vv{s}_1 + \vv{w}$, where $\vv{w}$ is some point in $\rs(\O_1)$ that is positive in this Euclidean space.  This expression implies that the special denominator $\denom$ is also a denominator for $\vv{w}$.  It then follows from the definition of $\vv{k}_1$ and this expression for $\vv{u}_1$ that the inequality $A_1 ( \vv{k}_1 p^{e-1} + \vv{k}^{\ast} ) < \vv{u}_1 p^e$ is equivalent to 
%
\begin{equation}
\label{target-inequality: e}
  A_1( - \tail{\vv{s}_1}_p + \vv{h}_1 ) \cdot p^{e-1} + A_1\vv{k}^{\ast} < \vv{w} p^e.
\end{equation}

Given that the target of $A_1$ is $\rs(\O_1) \oplus \rs(\O_1)^{\perp}$, it suffices to verify that \eqref{target-inequality: e} holds after projection to each of these Euclidean spaces.  We first consider the projection to $\rb(\O_1)^{\perp}$.  As $A_2$ is the collapse of $A_1$ along $\O_1$, the projection of $A_1 \vv{m}$ to $\rb(\O_1)^{\perp}$ equals $A_2 \vv{m}$ for every $\vv{m}$ in the domain of $A_1$.  In particular, the projection of $A_1( - \tail{\vv{s}_1}_p + \vv{h}_1 )$ to this subspace is $A_2 ( - \tail{\vv{s}_1}_p + \vv{h}_1 )$, which equals $-\vv{u}_2$, by our choice of $\vv{h}_1$.  Thus, projecting \eqref{target-inequality: e} to $\rs(\O)^{\perp}$ yields $-\vv{u}_2 \cdot p^{e-1} + A_2 \vv{k}^{\ast} < \vv{0}$, which holds as $\vv{k}^{\ast} \in \feas \IP(A_2, \vv{u}_2, p^{e-1})$.

We now consider the projection of \eqref{target-inequality: e} to $\rs(\O_1)$, and given that $\tail{\vv{s}_1}_p \geq \vv{0}$, it suffices to verify that the projection of the stronger inequality \[ \sum_{i=1}^{e} A_1 \vv{h}_i \cdot p^{e-i} = A_1 \vv{h}_1 \cdot p^{e-1} + A_1 \vv{k}^{\ast} < \vv{w}p^e \] to $\rs(\O)^{\perp}$ holds.  However, keeping in mind that $\ell$ is a denominator of $\vv{w}$, which is positive in $\rs(\O_1)$, every coordinate of the projection of $\vv{w} p^e$ to $\rs(\O_1)$ is at least $p^e / \ell$, while every coordinate of $\sum_{i=1}^{e} A_1 \vv{h}_i \cdot p^{e-i}$ is of the form $\sum_{i=1}^{e} \omega_i \cdot p^{e-i}$ for some $\omega_1, \cdots, \omega_e \in \Omega$.  Thus, the condition \eqref{p-big-2} tells us that this stronger inequality holds after projecting to $\rs(\O_1)$.

We have just verified that \eqref{target-inequality: e} holds throughout $\rs(\O_1) \oplus \rs(\O_1)^{\perp}$, which allows us to conclude the induction step, and hence, our proof.
\end{proof}

\newpage

\begin{lemma}
   \label{positive-polynomial: L}
   Given a real number $w > 0$, and a set $\Omega$ of real numbers that is bounded from above, there exists an integer $\beta = \beta(w, \Omega)$ satisfying the following condition\textup:
   If $p > \beta$, then for every integer $e \geq 1$, and for every $\omega_1, \ldots, \omega_e \in \Omega$, we have that $wp^{e} >  \omega_1 \cdot p^{e-1} + \cdots + \omega_{e-1} \cdot p + \omega_e$.
\end{lemma}


\begin{proof}
Let $\lambda$ be any positive upper bound for $\Omega$.  Suppose that $p > (w+\lambda)/w$, which after rearranging terms, is equivalent to the condition $w(p-1) - \lambda > 0$.  Multiplying this by $p^e$ and adding the positive number $\lambda$ then shows that
%
\[ wp^e ( p-1 ) - \lambda (p^e-1) > 0 \] for every integer $e \geq 1$.   If, in addition, we also suppose that $p -1 > 0$, then we may divide the above by this quantity to conclude that \[ w p^e - \lambda \cdot \frac{ p^e - 1}{p-1} = wp^e - \lambda p^{e-1} - \cdots - \lambda p - \lambda > 0 \] for every integer $e \geq 1$.   Moving every term but $wp^e$ to the right-hand side of this inequality, the resulting bound is enough to conclude our proof.
\end{proof}

%
\daniel[inline]{I ended up combining these.  We can split them up later if anyone (possibly, me) prefers this.  I also added the hypothesis that the pairs in the first path were small, which was missing.}
% 
\begin{corollary}\label{cor: iterated lifting}
Given a monomial matrix $A$, there exists an integer $\beta = \beta(A)$ such that the following hold for every $p > \beta$ and path \daniel{We haven't defined the graph $\graph_p(A)$ yet (i.e., the arrows and ``levels" of the vertices hasn't been discussed.  Once we do this, we should define ``$\in''$ to mean ``path in", as this might save us some writing, and it is intuitive.  What does everyone think?}\[ (A_1, \vv{u}_1) \to \cdots \to (A_e, \vv{u}_e)  \in \graph_p(A).\]  
\begin{enumerate}
\item If $(A_i, \vv{u}_i)$ is very small for every $1 \leq i \leq e$, then \[ \mu(A_1, \vv{u}_1, p^e) \geq \sum_{i=1}^e \mu(A_i, \vv{u}_i, p) \, p^{e-i}.\] 
\item If $(A_i, \vv{u}_i)$ is very small for $1 \leq i < e$, but the last pair $(A_e, \vv{u}_e)$ is not very small, then for every integer $s \geq 0$, 
 \[ \mu(A_1, \vv{u}_1, p^{e+s}) \geq \sum_{i=1}^{e-1} \mu(A_i, \vv{u}_i, p) \, p^{e+s-i} + p^{s+1}-1. \]
\end{enumerate}
\end{corollary}

%\begin{proposition}\label{prop: ineq for higher mus in terminal paths}  Given a monomial matrix $A$, there exists an integer $\beta = \beta(A)$ satisfying the following condition\textup:  If $p > \beta$ and
% \[
%  (A_1, \vv{u}_1) \to (A_2, \vv{u}_2) \to \cdots \to (A_e, \vv{u}_e)
% \]
% is a path in $\graph(A,p)$ such that  $(A_i, \vv{u}_i)$ is very small for $1 \leq i < e$, and such that the terminal vertex $(A_e, \vv{u}_e)$ is not very small, then  
%\[
% \mu(A_1, \vv{u}_1, p^{e+s}) \geq \mu(A_1, \vv{u}_1, p) p^{e+s-1} + \cdots + \mu(A_{e-1}, \vv{u}_{e-1}, p) p^{s+1} + p^{s+1} - 1.
%\] for every integer $s \geq 0$.
%\end{proposition}

\begin{proof} The proofs of each assertion are similar; we only prove the second, which is more involved.  Let $\beta = \beta(A)$ be as in \Cref{ILL: T}.  If $p > \beta$, then \Cref{ILL: T} tells us that there exists $\vv{k}_i \in \opt \IP(A_i, \vv{u}_i, p)$ for which \[ \vv{k}^{\ast} = \sum_{1 \leq i < e} \vv{k}_i \cdot p^{e-i} + \vv{k}_e \in \feas \IP(A_1, \vv{u}_1, p^e).\]

  The assumption on the points in the path implies that $\norm{\vv{k}_i} \leq p-1$ for all $1 \leq i < e$, while $\norm{\vv{k}_e} \geq p$.  Thus, there exists a point $\vv{g}$ in the domain lattice of $A$ such that $\norm{\vv{g}} = p-1$ and $\vv{0} \leq \vv{g} \leq \vv{k}_e$, with the last inequality strict in at least one coordinate, say, in the first coordinate.  Thus, $\vv{0} \leq \vv{g} + \vv{e}_1 \leq \vv{k}_e$.

Fix an integer $s \geq 0$, and set   
%
\[ \vv{h} = \sum_{1 \leq i < e} \vv{k}_i \cdot p^{e+s-i} + (\vv{g} + \vv{e}_1) \cdot p^{s} - \vv{e}_1 \]
%
The bound $\vv{0} \leq \vv{g} + \vv{e}_1 \leq \vv{k}_e$ implies that $\vv{h} \leq \vv{k}^{\ast}  p^s$, and the feasibility of $\vv{k}^{\ast}$ for $\IP(A_1, \vv{u}_1, p^e)$ then implies that  $\vv{h}$ is feasible for $\IP(A_1, \vv{u}_1, p^{e+s})$.  To see that $\vv{h}$ is also feasible for the arithmetic version of this program, simply observe that the base $p$ expansion of $\vv{h}$ is given by 
%
\[ \vv{h} = \sum_{1 \leq i < e} \vv{k}_i \cdot p^{e+s-i} + \vv{g} \cdot p^{s} + (p-1) \vv{e}_1 \cdot p^{s-1} + \cdots + (p-1) \vv{e}_1 \]
%
and recall that $\norm{\vv{k}_i} \leq p-1$ for every $1 \leq i < e$.  Therefore, 
%
\[ \mu(A_1, \vv{u}_1, p^{e+s}) \geq \norm{\vv{h}} = \sum_{1 \leq i < e} \mu(A_i, \vv{u}_i, p) \cdot p^{e+s-i}+ p^{s+1}-1. \]
%

\begin{corollary}
Given a monomial matrix $A$, there exists an integer $\beta = \beta(A)$ with the following property\textup: If $p > \beta$ and $(A, \vv{u})$ is small, but not very small, then $\mu(A,u,p^e) = p^e-1$ for every $e \geq 1$.

\end{corollary}

\end{proof}


%\emily[inline]{This is a terminating path in $\widehat{\graph}(A)$ (Pedro's version! i.e., all pairs are small and the last is medium-small)} 
%\daniel[inline]{I restated this so that the graph always terminates at a medium-small vertex, even when $e = 1$.  This should then imply that the critical exponent of a medium small pair equals $1$, which would allow us to remove an earlier theorem}

\newpage
\subsection{The Sprouting graph for a pair}
\begin{definition}
   Suppose that $(A, \vv{u})$ is very small.
   For $e \geq 0$, we define the set $\widehat{\graph}^e(A,\vv{u},p)$ inductively as follows:
\begin{enumerate}
\item $\widehat{\graph}^0(A, \vv{u}, p)$ consists of the single monomial pair $(A, \vv{u})$.
\item Suppose that $\widehat{\graph}^e(A, \vv{u}, p)$ has been defined for some integer $e \geq 0$, and let $S$ be the set of all $p$-sprouts of all monomial pairs in $\widehat{\graph}^e(A, \vv{u}, p)$.
If  $S$ is empty (that is, $\widehat{\graph}^e(A, \vv{u}, p)$ itself is empty) or contains a pair that is not very small, then \[ \widehat{\graph}^{e+1}(A, \vv{u}, p) = \emptyset.\]  
\emily{or say $\emptyset$ whenever $\graph^e(A, \vv{u}, p)$ is empty, or contains a medium-small pair}
Otherwise, $\widehat{\graph}^{e+1}(A, \vv{u}, p)$ is the set of all sprouts $(B, \vv{v})$ in $S$ satisfying the following conditions:    

\begin{enumerate}
\item Among all pairs in $S$, the value of  $\ft{B}{\vv{v}}$ is maximal.
\item Among all pairs in $S$ that achieve this maximum, the value of $\delta(B, \vv{v}, p)$ is minimal.
\end{enumerate}
Consequently, the value $\mu(B, \vv{v},p)$ is maximized among all elements in $S$ when $p \gg 0$. 
\end{enumerate}
\end{definition}


\begin{proposition}
   Given a monomial matrix $A$, there exists an integer $D$ such that $\widehat{\graph}(A, \vv{u}, p) = \widehat{\graph}(A, \vv{u}, q)$ for every pair $(A, \vv{u})$ whenever $p \equiv q \bmod D$.
\end{proposition}

\alert[inline]{Include the proof.  It has to do with some finiteness property of $\ip$.}


% \begin{corollary}
% If $(A, \vv{u})$ is a monomial pair and $p \gg 0$, then
% \[ \val \IP_p(B, \vv{v}p) = \ft{B}{\vv{v}} \cdot p - \delta_p(B, \vv{v}) \] for any vertex $(B, \vv{v})$ of $\widehat{\graph}_p(A, \vv{u})$.    In addition, if $(B, \vv{v})$ and $(D, \vv{z})$ are any two such vertices, then $\val \IP_p(B, \vv{v}) < \val \IP_p(D, \vv{z})$ if and only if $\ft{B}{\vv{v}} < \ft{D}{\vv{z}}$, or these two quantities agree and $\delta_p(B, \vv{v}) > \delta_p(D, \vv{z})$.  
% \end{corollary}


\begin{lemma}\label{lem: upper bound for higher mu}
   Given a monomial matrix $A$, there exists an integer $\beta= \beta(A)$ for which the following holds\textup:
   For each $p>\beta$ and $e\ge 1$, if $(A, \vv{u})$ is a very small monomial pair and $(A_1, \vv{u}_1) \to \cdots \to (A_e, \vv{u}_e)$ is a path in $\widehat{\graph}(A, \vv{u}, p)$,  then 
   \[
      \mu(B, \vv{v}, p^e) \le \mu(A_1, \vv{u}_1, p)p^{e-1} + \mu(A_2, \vv{u}_2, p)p^{e-2} + \cdots + \mu(A_{e}, \vv{u}_{e}, p)
   \]
   for any vertex $(B, \vv{v})$ of $\widehat{\graph}(A, \vv{u}, p)$ on the same level as $(A_1, \vv{u}_1)$.
\end{lemma}

\begin{proof}
   Choose $\beta = \beta(A)$ so that the conclusions of \Cref{arithmetic uniform value and image: T,cor: upper bound for higher mus} \pedro{Maybe more?} hold for each one of the finitely many pairs in $\widehat{\graph}(A, \vv{u},p)$ whenever $p > \beta$, and fix such $p$.
    By virtue of \Cref{arithmetic uniform value and image: T} and the construction of $\widehat{\graph}(A,\vv{u},p)$, the assumption that $(A_1, \vv{u}_1)$ and $(B, \vv{v})$ lie on the same level implies that $\mu(B,\vv{v},p) = \mu(A_1, \vv{u}_1, p)$, proving the result for $e = 1$.

    Suppose that $e \geq 2$ and the result holds for paths of length $e-2$.
    \Cref{cor: upper bound for higher mus} tells us that
    \begin{align*}
      \mu(B,\vv{v},p^e) &\le \mu(B,\vv{v},p) p^{e-1} + \max_{\sproutsfrom{(C,\vv{z})}{(B,\vv{v})}} \ \mu(C,\vv{z},p^{e-1}) \\
      &= \mu(A_1,\vv{u}_1,p) p^{e-1} + \max_{\sproutsfrom{(C,\vv{z})}{(B,\vv{v})}} \ \mu(C,\vv{z},p^{e-1}),
    \end{align*}
    and to complete our inductive step, it suffices to show that
    \begin{equation}\label{ineq}
        \mu(C,\vv{z},p^{e-1}) \le \mu(A_2,\vv{u}_1,p) p^{e-2} + \cdots + \mu(A_e,\vv{u}_e,p)
    \end{equation}
    for each $(C,\vv{z})$ sprouting from $(B,\vv{v})$.
    
    Towards this, first note that if $(C, \vv{z})$ does not lie in $\widehat{\graph}(A,\vv{u},p)$, then \Cref{cor: mu comparison} implies that $\mu(C, \vv{z},p^{e-1}) < \mu(A_2,\vv{u}_2, p^{e-1})$, and the induction hypothesis applied to $(A_2, \vv{u}_2) \to \cdots \to (A_e, \vv{u}_e)$ and $(A_2,\vv{u}_2)$ itself gives \eqref{ineq}.
    On the other hand, if $(C, \vv{z})$ lies in $\widehat{\graph}(A, \vv{u},p)$, then it lies on the same level as $(A_2, \vv{u}_2)$, and  our induction hypothesis applied to the path $(A_2, \vv{u}_2) \to \cdots \to (A_e, \vv{u}_e)$ and the point $(C, \vv{z})$ once again gives us \eqref{ineq}, completing the proof.
\end{proof}

%%% OLD PROOF
% Choose $p \gg 0$ so that the conclusions of Corollary ??\daniel{The preceding corollary?} hold for $(A, \vv{u})$.  In this case, the assumption that $(A_1, \vv{u}_1)$ and $(B, \vv{v})$ lie in the same level implies that $\ft{A_1}{\vv{u}_1} = \ft{B}{\vv{v}}$ and $\delta_p(A_1, \vv{u}_1) = \delta_p(B, \vv{u})$, and so 
% \[ \val \IP_p(B, \vv{v}p) = \val \IP_p (A_1, \vv{u}_1 \cdot p) = \ft{A_1}{\vv{u}_1} \cdot p - \delta_p(A_1, \vv{u}_1). \] 

% We will induce on $e \geq 1$.  The above observation settles the base case $e=1$.  Next, suppose that $e \geq 2$, and consider a path  \[ (A_1, \vv{u}_1) \to (A_2, \vv{u}_2) \to \cdots \to (A_e, \vv{u}_e)\] in $\graph_p(A, \vv{u})$.  If $C$ is the collapse of $B$ along the face $\O = \mf(B, \vv{u})$, then Corollary ?? \daniel{Which Corollary is this referring to?} and the above expression for $\val \IP_p(B, \vv{v}p)$ tell us that the value of the arithmetic program $\IP_p(B, \vv{v}p^{e+1})$ is at most
% %
% \[  \left( \ft{A_1}{\vv{u}_1} \cdot p - \delta_p(A_1, \vv{u}_1) \right) \cdot p^e +  \max_{\vv{z}} \val \IP_p(C, \vv{z}p^e) \]
% %
% where the maximum is over all $\vv{z} \in \Delta_p(B, \vv{v})$.   Therefore, to complete our inductive step, it suffices to show that this maximum is at most
% %
% \begin{equation}
% \label{target bound: e}
% \left( \sum_{s=2}^e \frac{ \ft{A_s}{\vv{u}_s}  \cdot p - \delta_p(A_s, \vv{u}_s)}{p^s} \right) \cdot p^{e-1}.  \end{equation}

% Towards this, first note that if $(C, \vv{z})$ is not among the vertices of $\graph_p$ of level equal to that of $(A_2, \vv{u}_2)$ for any $\vv{z} \in \Delta_p(B, \vv{v})$, then Corollary \!{} and our choice of $p \gg 0$ implies that $\val \IP_p(C, \vv{z}p) < \val \IP_p(A_2, \vv{u}_2 \cdot p)$ for every $\vv{z} \in \Delta_p(B, \vv{z})$.  In light of this, Corollary \!{} then tells us that 
% \[  \max_{\vv{z}} \val \IP_p(C, \vv{z}p^e) < \val \IP_p(A_2, \vv{u}_2 \cdot p^e)\]  
% and our induction hypothesis applied to the path 
% \[ (A_2, \vv{u}_2) \to \cdots \to (A_e, \vv{u}_e) \] and the initial point $(A_2, \vv{u}_2)$ itself then tells us that the value of the program $\IP_p(A_2, \vv{u}_2 \cdot p^e)$ is at most the quantity in \eqref{target bound: e}.  

% On the other hand, if $(C, \vv{z})$ is a vertex of $\graph_p(A, \vv{u})$ of level equal to that of $(A_2, \vv{u}_2)$ for some $\vv{z} \in \Delta_p(B, \vv{v})$, then our induction hypothesis applied to the path 
% $(A_2, \vv{u}_2) \to \cdots \to (A_e, \vv{u}_e)$ and the point $(C, \vv{z})$ once again tells us that the value of the program $\IP_p(A_2, \vv{u}_2 \cdot p^e)$ is at most the quantity in \eqref{target bound: e}.  With this, we conclude the induction step, and hence, our proof. 
% \end{proof}



\begin{theorem}\label{thm: formula for higher mu}
   Given a monomial matrix $A$, there exists an integer $\beta= \beta(A)$ for which the following holds\textup:
   For each $p>\beta$ and $e\ge 1$, if $(A, \vv{u})$ is a very small monomial pair and $(A_1, \vv{u}_1) \to \cdots \to (A_e, \vv{u}_e)$ is a path in $\widehat{\graph}(A, \vv{u}, p)$,  then 
   \[ 
      \mu(A_1, \vv{u}_1, p^e) = \mu(A_1,\vv{u}_1,p)p^{e-1} + \cdots + \mu(A_{e-1},\vv{u}_{e-1},p)p + \mu(A_e,\vv{u}_e,p).
   \]
   If, in addition, that path is terminal \textup(that is, $(A_e,\vv{u}_e)$ is not very small\textup), then
      \[ 
 \mu(A_1, \vv{u}_1, p^{e+s}) = \mu(A_1, \vv{u}_1, p) p^{e+s-1} + \cdots + \mu(A_{e-1}, \vv{u}_{e-1}, p) p^{s+1} + p^{s+1} - 1
\]
for every nonnegative integer $s$.
\end{theorem}

\begin{proof}
   The first identity follows from \Cref{cor: iterated lifting}(1) and \Cref{lem: upper bound for higher mu}, while the second follows from \Cref{cor: iterated lifting}(2) and the first, together with the fact that $\mu(A_1, \vv{u}_1, p^{e+s}) \le \mu(A_1, \vv{u}_1, p^{e}) p^s+p^s-1$, which follows from the second inequality in \Cref{natural bounds: C}.
\end{proof}

\alert[inline]{
\begin{corollary}\label{cor: constant mus}
   If $(A,\vv{u})$ is a small monomial pair and  $\beta = \beta(A)$ is as in \Cref{lem: upper bound for higher mu}, then $\crit$ and $\mu$ are constant on each level of $\widehat{\graph}(A,\vv{u},p)$ for every $p\ge \beta$. 
\end{corollary}
%\todo[inline]{Restate more precisely}
\pedro[inline]{
   I'm not a believer anymore.
   If $(A_1,\vv{u}_1)$ and $(B,\vv{v})$ are as in \Cref{lem: upper bound for higher mu}, we only get the inequality $\mu(B,\vv{v},p^e) \le \mu(A_1,\vv{u}_1,p^e)$, and to conclude that we have equality we'd need to know that there is a path of length $e-1$ starting at $(B,\vv{v})$.
   But we don't know if we have this kind of uniformity in the graph.
}

\daniel[inline]{I think this can be remedied, but we will need to define the graph in a different way, to allow for paths that terminate and infinite paths at the same time.  The point is that at some fixed level $e$, a vertex should sprout if and only if that vertex is very small.  This sounds more like what you were suggesting in Lawrence.}
}
\newpage


\comment[inline]{The point of this Lemma is to show positivity of the coefficients in the polynomials that define the $\mu$'s. A consequence is that if $\ideala$ is $\idealm$-primary and homogeneous, then all coefficients of every intermediate power of $p$ in this polynomials vanishes.}

\begin{lemma}  If  $p>0$ is prime and $(B, \vv{v})$ is a $p$-sprout of  $(A, \vv{u})$, then \[ \delta(A, \vv{u}, p) \geq \ft{B}{\vv{v}}\]
with equality if $A$ is the monomial matrix associated to a monomial ideal that is homogeneous with respect to some positive $\ZZ$-grading, and primary to the ambient homogeneous maximal ideal.
\end{lemma}

\begin{proof}
By definition of $p$-sprout,  $B$ is the collapse of $A$ along the face $\O = \mf(A, \vv{u})$ of the Newton polyhedron $\N$ associated to $A$.  Suppose that $A$ has $d$ rows, and let $\collapse{X}$ denote the collapse of a subset $X$ of $\RR^d$ along $\O$.  

If $\vv{a} \in \RR^d$ defines the face $\O$ in $\N$, then \Cref{collapse of Newton polyhedron: L}  states that $\collapse{\vv{a}}$ defines the standard face $\collapse{\O}$ of $\collapse{\N}$, the Newton polyhedron associated to $B$, and \Cref{FT descriptions: P} then implies that \[\ft{B}{\vv{v}} \leq \iprod{\collapse{\vv{a}}}{\vv{v}}.\]

Thus, it suffices to show that $\iprod{\collapse{\vv{a}}}{\vv{v}} \leq \delta(A, \vv{u}, p)$.  However, by definition of $p$-sprout, $\vv{v} \in \Delta(A, \vv{u}, p)$, and so fixing a point $\vv{s} \in \mc_{\QQ}(A, \vv{u})$, we may write $ \vv{v} = B \tail{\vv{s}}_p - B \vv{h}$ for some $\vv{h}$  optimal for $\ip = \ip(A, \vv{u}, \vv{s}, q)$.  Our choice of $\vv{a}$ guarantees that the inner product of $\collapse{\vv{a}}$ with each column of $B$ is at least one, with equality whenever that column lies on $\collapse{\O}$.  Arguing as in the proof of \Cref{bounded value: L}, one may show that $\iprod{\collapse{\vv{a}}}{B \tail{\vv{s}}_p} = \norm{\tail{\vv{s}}_p}$ and \[ \iprod{\collapse{\vv{a}}}{ B \vv{h}} \geq \norm{\vv{h}} = \val \ip \] 
which allows us to conclude that \[ \iprod{\collapse{\vv{a}}}{\vv{v}} \leq \norm{\tail{\vv{s}}_p} - \val \ip= \delta(A, \vv{u}, p).\]

We now address the last assertion:  If $A$ satisfies these additional conditions, then homogeneity implies that the convex hull of the columns of $A$ is a proper face $\O$ of $\N$.  The $\mathfrak{m}$-primary assumption further implies that $\O$ is a facet, and that $\mf(A, \vv{z}) = \O$ for every $\vv{z} \in \ZZ_+^d$.  Furthermore, the positivity of the grading implies that the point $\vv{a} \in \RR^d$ defining this face must have positive coordinates, and so $\O$ must be bounded.  In this case, collapsing along this face is simply the identity map on $\RR^d$, and so in particular, $B=A$.  Given this, one may retrace the steps above to see that every inequality involving the inner product of $\vv{a} = \collapse{\vv{a}}$ with another point must be, in fact, an equality.  The details are left to the reader.
\end{proof}


\todo[inline]{Point out that the levels of $\widehat{\graph}(A, \vv{u})$ are eventually periodic. This will give an independent proof the rationality of critical exponents.  The way we present a formula for critical exponents may need this observation.}

\section{Fractal linear programs}

\emily[inline]{Here, I am working to fill in the details of the proof I sketched out below, sticking with $[0,1]^n$ for now (but we can modify it at any point).}


\begin{definition}
 The \emph{Sierpi\'nski $p$-gasket} in $[0,1]^n$ is the set $\sierp_p$ consisting of all points $\vv{t}\in [0,1]^n$ for which there exist a sequence of points $\{ \vv{t}_e \}_{e=1}^\infty$ in $\NN^n$ for which all $\norm{\vv{t}_e} < p$ and 
 \[
\vv{t} = \frac{\vv{t_1}}{p} +\frac{\vv{t_2}}{p^2}+\cdots +\frac{\vv{t_e}}{p^e} + \cdots.  
 \]
\end{definition}


From the definition, we immediately see that a point in the unit cube $[0,1]^n$ is in $\sierp_p$ if the unique nonterminating base $p$ expansions of its digits \emph{add without carrying}.  However, this is not a complete description of $\sierp_p$.  For instance, if $p=2$, then $\frac{1}{4} = \frac{1}{2^3} + \frac{1}{2^4} + \frac{1}{2^5} + \cdots$ added to itself carries at infinitely many places, yet we see that $\left(\frac{1}{4}, \frac{1}{4}\right)$ is in the Sierpi\'nski $2$-gasket in $\RR^2$ after writing one summand simply as $\frac{1}{4} = \frac{1}{2^2}$.


This description of the Sierpi\'nski $p$-gasket in terms of ``expansions'' is not hard to translate geometrically into its fractal description. 
For instance, $\sierp_2$ in $[0,1]^2$ is the familiar Sierpi\'nski triangle:   
The points $\vv{t}$ in the unit cube that have \emph{no} expansion $\vv{t} = \frac{\vv{t_1}}{2} +\frac{\vv{t_2}}{2^2}+\cdots +\frac{\vv{t_e}}{2^e} + \cdots$
 for which all $\vv{t_e} \in \NN^2$, and $\norm{\vv{t_1}} < 2$ are precisely 
the points lying above the line $x+y=1$; i.e., we are removing the triangle given by $x+y>1$.  
At the next stage, the points for which there are no expansion for which 
$\norm{\vv{t_1}} < 2$ and  $\norm{\vv{t_2}} < 2$ further removes the similar triangle of points $(x,y)$ with $x, y < \frac{1}{2}$ and $x+y > \frac{1}{2}$, and iteratively, the stages can be described analogously.
Notice, in particular, that since they can be realized by removing a union of open sets from $[0,1]^n$, all $\sierp_p$ are compact.  






The critical exponent of a monomial pair $(A, \vv{u})$ can be computed in terms of the Sierpi\'nski $p$-gasket, providing a geometric realization of this value.
Toward making this relation precise, consider the following optimization problem, which adds the extra ``fractal'' constraint from the definition of $\sierp_p$ to 
the linear program $\LP(A, \vv{u})$; we call this a \emph{fractal linear program}.

\begin{definition}
The fractal linear program $\fip_p(A,\vv{u})$ consists of maximizing $\vv{k}\mapsto \norm{\vv{k}}$, subject to the constraints $A\vv{t}\le \vv{u}$ and $\vv{t}\in \sierp_p$.
\end{definition}

\begin{remark}
The feasible set of $\Sigma_p(A, \vv{u})$ is the intersection of the feasible set of the linear program $\LP(A, \vv{u})$ with the Sierpi\'nski $p$-gasket, and since this feasible set is compact, the program $\Sigma_p(A, \vv{u})$ has a nonempty optimal set.
\end{remark}

\begin{proposition}  
Given a monomial pair $(A, \vv{u})$, we have that 
\[\crit(A,\vv{u}) = \val\fip_p(A,\vv{u}).\]
\end{proposition}


\pedro[inline]{
   OUTLINE:
   \begin{itemize}
      \item The Sierpinsky $p$-gasket in $\RR^n$ is the set $\sierp_p$ consisting of every point $\vv{t}\in \RRnn^n$ that has \ul{\emph{some}} base $p$ expansion $\vv{t} = \down{\vv{t}} + \frac{\vv{d_1}}{p} +\frac{\vv{d_2}}{p^2}+\cdots$ with ``digits'' $\vv{d}_i$ of norm $<p$.
      This is typically defined in $[0,1]^n$, but I see no harm in extending it to $\RRnn^n$.
      \item The fractal linear program $\fip_p(A,\vv{u})$ consists of maximizing $\vv{k}\mapsto \norm{\vv{k}}$, subjected to the constraints $A\vv{t}\le \vv{u}$ and $\vv{t}\in \sierp_p$.
      Since the feasible set is compact, this program has a nonempty optimal set.
      \item For each $q=p^e$, $\frac{1}{q}\cdot\feas\IP_p(A,\vv{u}q)$ is contained in the feasible set for $\fip_p(A,\vv{u})$.
      So, $\val\fip_p(A,\vv{u}) \ge \displaystyle \lim_{q\to \infty}\frac{\val\IP_p(A,\vv{u}q)}{q} = \crit(A,\vv{u})$.
      \item It would be nice if we had equality in general, but I'm not super hopeful\ldots
      To prove equality, we'd pick an optimal point $\vv{t}$ for $\fip_p(A,\vv{u})$, and take truncations (of the nonterminating base $p$ expansion, as usual), to obtain a sequence $(\frac{\vv{v}_q}{q})_q$ that converges to $\vv{t}$.
      If that expansion already has ``digits'' of norm $<p$, it's all cool: then each truncation $\frac{\vv{v}_q}{q}$ lies in $\frac{1}{q}\cdot\feas\IP_p(A,\vv{u}q)$, so
      \[\val \fip_p(A,\vv{u}) = \norm{\vv{t}} = \lim_{q\to\infty}\norm{\frac{\vv{v}_q}{q}} \le \lim_{q\to \infty}\frac{\val\IP_p(A,\vv{u}q)}{q} = \crit(A,\vv{u}).\]
      Otherwise, we'd have to modify the expansion of $\vv{t}$, but it's hard (maybe impossible?) to do that in a way that the $\vv{v}_q$ all satisfy $A\vv{v}_q < q\vv{u}$ (at least for $q\gg 0$).
      (Need to think more about this\ldots)
      % \item In the case of a very small pair, sprouting and the lifting lemma allows us to explicitly construct an optimal point for  $\fip_p(A,\vv{u})$, when $\widehat{\graph}(A,\vv{u})$ is finite.
   \end{itemize}
}
\emily[inline]{
Let $\Xi_p(A, \vv{u})$ be defined the same way as $\Sigma_p(A, \vv{u})$, but with $A \vv{t} \leq \vv{u}$ replaced with $A \vv{t} < \vv{u}$.  Since $\Xi_p(A, \vv{u})$ lives in the compact set  $\Sigma_p(A, \vv{u})$ and the objective function is continuous, we can define $\val \Xi_p := \sup_{\vv{j} \in \Xi_p}\norm{\vv{j}} < \infty$, and since 
$\Sigma_p(A, \vv{u})$ is the closure of $\Xi_p(A, \vv{u})$, we have that $\val \Xi_p(A, \vv{u}) = \val \Sigma_p(A, \vv{u})$. 
Using the analog of Pedro's above argument, we directly see that $\val \Xi_p(A, \vv{u}) \geq \crit(A, \vv{u})$.  Now, for any $\vv{t} \in \Xi_p(A, \vv{u})$, fix a base $p$ expansion for $\vv{t}$ that satisfies the carrying condition in $\Xi_p(A, \vv{u})$, and let $\vv{t}^\star_q$ be the $q$-th truncation of $\vv{t}$ with respect to this expansion.  Then $q \vv{t}^\star_q \in \Pi_p(A, \vv{u}q)$ (note that it is possible that $\vv{t}^\star_q = \vv{t}$, so it is important that  $\leq$ was changed to $<$ ). Hence $\val \Pi_p(A, \vv{u}q) \geq q \norm{\vv{t}^\star_q}$ for all $q$, and by dividing by $q$ and taking limits, we conclude that $\crit(A, \vv{u}) \geq \norm{\vv{t}}$, and since $\vv{t}$ was arbitrary, 
$\crit(A, \vv{u}) \geq \val \Xi_p(A, \vv{u} q)$.}

\pedro[inline]{We could include a 2D example, with pictures, such as the following, where
   \[
      A =
      \begin{pmatrix}
        1&11\\ 5&10\\ 9&8\\ 11&1
      \end{pmatrix}
   \]
}

\daniel[inline]{These look cool!  What are the orange regions?  Areas that you know for sure contain the optimal set?  Also, I've seen some pictures of Sierpinski gaskets when $n=3$.  I suspect that this might be possible to do in Mathematica, but I also wouldn't be surprised if it were hard.  If this were possible, to we would also still need to intersect with a polytope to illustrate an AIP with $n=3$.  This may not be reasonable, or even possible.}

\begin{figure}[h]
  \centering
  \includegraphics[width=.48\textwidth]{Pictures/ex1_char2.pdf}\hskip .04\textwidth
  \includegraphics[width=.48\textwidth]{Pictures/ex1_char3.pdf}
  \\[.04\textwidth]
  \includegraphics[width=.48\textwidth]{Pictures/ex1_char5.pdf}\hskip .04\textwidth
  \includegraphics[width=.48\textwidth]{Pictures/ex1_char7.pdf}
\end{figure}

\newpage

\emily[inline]{

\textbf{Important Questions}.

\begin{enumerate}
 \item Does a medium-small pair always have a medium-small sprout?
 We think the answer is NO:  
 Let $A = \begin{bmatrix} 3 & 0 \\ 0 & 3 \end{bmatrix}$ and $\vv{u} = (2,2)$, so that 
$(A, \vv{u})$ is small but not very small.  Then the unique minimal coordinate is $\vv{s} = (2/3,2/3)$, so that if $p=2 \bmod 3$, then $[\vv{s}]_p = (2[p\%3]/3, 2[p\%3]/3) = (1/3,1/3)$. 

The value of $\Theta(A, \vv{u}, \vv{s}, p)$ is $0$
using the bounds in this paper, and from this, we can find that the only element of $\Delta(A, \vv{u}, \vv{s}, p)$ is $(1,1)$, which is very small. 

\item Is it true that if some digit of a critical exponent of the monomial ideal $\ideala$ equals $p-1$, then \emph{all subsequent digits} must also be $p-1$.  This seems to be true if we run into a \emph{medium small} point.  Are there points $\vv{v}$ with $\mu(A,\vv{v}, p) = p-1$ where $(A,\vv{v})$ is not medium small?  Sure, look at $A = \begin{bmatrix} 2 & 0 \\ 0 & 2 \end{bmatrix}$ and $\vv{v} = (1,1)$.  Then our Frobenius examples paper should tell us that $(A, \vv{v})$ is very small but $\mu(A, \vv{u}, p)$ should equal $1$ often.
\item We saw earlier that a medium small pair need not sprout a medium small pair.  But does a pair $(A, \vv{u})$ that is small and satisfies $\mu(A, \vv{u}, p) = p-1$ then must it sprout a pair $(B, \vv{v})$ with $\mu(B, \vv{v}, p) = p-1$?

\item Pedro pointed out the better question is that if $(A, \vv{u})$ is small and $\mu(A, \vv{u}, p) = p-1$, then is the whole critical exponent $\crit(A, \vv{u}) = 1$?
\item The answer to the last question is FALSE:  In our Frobenius examples paper, there is a critical point $1-(1/p^2) = p-1 : p-2 : \overline{p-1}$.
\end{enumerate}  
}


{\small
\bibliographystyle{amsalpha}
\bibliography{bibdatabase}
}	


\end{document}

\newpage
\section{Working in Lawrence}

Suppose that $\ideala$ is $\idealm$-primary.  If $\vv{u} \in \NN^d_+$, then this forces $\O = \mf(A, \vv{u})$ to be compact.  Suppose $\vv{u} \in \NN^d_+$ satisfies $\ft{A}{\vv{u}} \leq 1$.  Then 
%
\[ \mu_{\ideala}^{\vv{u}}(p) = \nu_{\ideala}^{\vv{u}}(p) =  \ft{A}{\vv{u}} \cdot p - \delta(A, \vv{u}, p) \] and 
 \[ \ideala^{[\mu_{\ideala}^{\vv{u}}(p) ]} \equiv \langle x^{\vv{u}p - \vv{z}} : \vv{z} \in \Delta(A, \vv{u}, p) \rangle \bmod \diag(\vv{u}p) \]
%
A key ingredient is the identity 
\[ \crit(\ideala ,\vv{u}) = \frac{ \mu_{\ideala}^{\vv{u}}(p)}{p} + \frac{\max \{ \crit(\ideala, \vv{z}) : \vv{z} \in \Delta(A, \vv{u}, p) \}}{p} \]

We want to compute this max.  If there exists a point $\vv{z} \in \Delta(A, \vv{u}, p)$ that is small, but not very small, then the max equals $1$.  Otherwise, suppose that every point in $\Delta(A, \vv{u}, p)$ is very small.  

Let's look at 
\[ \max \{ \crit(\ideala, \vv{z}) : \vv{z} \in \Delta(A, \vv{u}, p) \} \]
There exists $\vv{z}^{\ast} \in \Delta(A, \vv{u}, p)$ such that \daniel{If $p \gg 0$ then we can pick $\vv{z}^{\ast}$ so that it is independent of $p$.}

\[ \max \{ \crit(\ideala, \vv{z}) : \vv{z} \in \Delta(A, \vv{u}, p) \} = \frac{\mu_{\ideala}^{\vv{z}^{\ast}}(p)}{p} + \frac{\max \{  \crit(\ideala, \vv{w}) : \vv{w} \in \cup_{\vv{z} \in \Delta(A, \vv{u}, p)} \Delta(A, \vv{z}, p)\} }{p} \]

Substitute this into formula for $\crit(\ideala, \vv{u})$ to get that
%
\[
\crit(\ideala, \vv{u}) =  \frac{ \mu_{\ideala}^{\vv{u}}(p)}{p} +  \frac{ \mu_{\ideala}^{\vv{z}^{\ast}}(p)}{p^2} + \frac{\max \{  \crit(\ideala, \vv{w}) : \vv{w} \in \cup_{\vv{z} \in \Delta(A, \vv{u}, p)} \Delta(A, \vv{z}, p)\} }{p^2}
\]
%

\emily[inline]{If $(A, \vv{u})$ is small but not very small, then $\mu_\ideala^{\vv{u}}(p) = p-1$, so $\mu_\ideala^{\vv{u}}(p) \neq \nu_\ideala^{\vv{u}}(p)$.
In this case, although our description of $\ideala^{\nu_\ideala^{\vv{u}}(p)}$ does not depend on $p$, we \emph{can} have that the generators of $\ideala^{\mu_\ideala^{\vv{u}}(p)}
= \ideala^{p-1}$ depend on $p$:  For instance, if $\ideala = \langle x, y, \rangle$, then $\nu_\ideala^{\vv{u}}(p) = 2p-2$  and $\mu_\ideala^{\vv{u}}(p) = p-1$.  Moreover, $x^{p-(p+1)/2}y^{p-(p+1)/2} \in \ideala^{p-1}$.
(Actually, all minimal generators of $\ideala^{p-1}$ depend on $p$.)
}


\begin{definition}  We are trying to define a sequence of subsets of the union of \[ \Delta(A) := \cup_{\vv{z} \in \NN^d_+, p} \Delta(A, \vv{z}, p)\] which is a finite set, with $\{ \vv{u} \}$. \daniel{This $\vv{u}$ is probably already in the first set, if we allow $p \equiv 1$ mod whatever.}

\begin{enumerate}
\item  $\graph_1 = \{ \vv{u} \}$.  We are assuming that $(A, \vv{u})$ is small.
\item Suppose $\graph_e$ has been defined for some $e \geq 1$.  Then 
\[ \graph_{e+1} = \begin{cases} \emptyset & \exists \text{ medium small point in $\graph_e$}\\ \bigcup \limits_{\vv{z} \in \graph_e} \Delta(A, \vv{z},p) & \text{otherwise} \end{cases} \]
\end{enumerate}

\end{definition}


For $\graph_e \neq \emptyset$, set $\mu_e = \max \{ \mu_\ideala^{\vv{z}}(p) \ : \ \vv{z} \in \graph_e \}$.

If $\graph_t = \emptyset$ for some $t \geq 1$, suppose that this is the smallest $t$ with this property. Then 
\[
 \crit(\ideala, \vv{u}) = \left( \sum_{i=1}^{t-1} \frac{\mu_i}{p^i}\right) +  \frac{1}{p^t}.
\]

Otherwise, since each $\graph_e$ is a subset of the finite set $\Delta(A)$, there are only finitely many such distinct sets.  Hence there exist $e, s \geq 1$ for which $\graph_{e+s} = \graph_e$.  
Then 
\[
 \crit(\ideala, \vv{u}) = \sum_{i = 1}^\infty \frac{\mu_i}{p^i} = \left( \sum_{i=1}^{e-1} \frac{\mu_i}{p^i}\right) +  \frac{p^s}{p^s-1} \left(\sum_{i=e}^{e+s-1} \frac{\mu_i}{p^i}\right).
\]


\newpage

\textbf{A more intuitive proof that} $\mu(\ideala, \vv{u}, p) \leq \mu(\collapse{\ideala}, \collapse{\vv{u}}, p)$.

\vspace{.3cm}

Suppose that $\ft{A}{\vv{u}} \leq 1$.  
We know the following about $(\collapse{A}, \collapse{\vv{u}})$:
\begin{enumerate}
 \item $\mu(\collapse{A}, \collapse{\vv{u}}, p) = \ft{\collapse{A}}{\collapse{\vv{u}}} p - \delta(\collapse{A}, \collapse{\vv{u}},p)$.
 \item $\collapse{\ideala}^{\mu(\collapse{A}, \collapse{\vv{u}}, p)} \equiv \langle x^{\collapse{\vv{u}} p - \vv{z}} : \vv{z} \in \Delta(\collapse{A}, \collapse{\vv{u}}, p) \rangle \bmod \diag(\vv{u}p)$.
 Moreover, fix any such $x^{\collapse{\vv{u}} p - \vv{z}}$.  Then for every representation \[\vv{z} = \collapse{A} [\vv{s}]_q - \collapse{A} \vv{h}
 \]
 with $\vv{h} \in \opt \ip(A, \vv{u}, \vv{s}, p)$, there exists $\beta$ (that depends on this representation) such that 
 \[
  x^{A(\vv{s}p-[\vv{s}]_p + \vv{h})} \in \ideala^{\mu(\collapse{\ideala}, \collapse{\vv{u}}, p)} \setminus \diag(\vv{u}p)
 \]
 for all $p > \beta$.
\end{enumerate}

\begin{lemma}[A lifting lemma]
There exists $\beta = \beta(A)$ with the following property\textup:  For all $\vv{z}\in \Delta(A, \vv{u}, q)$, there exists some monomial in $\ideala^{\nu(\collapse{\ideala}, \collapse{\vv{u}}, q)} \setminus \diag(\vv{u}q)$ that lifts $x^{\collapse{\vv{u}}q-\vv{z}} \in \collapse{\ideala}^{\nu(\collapse{\ideala}, \collapse{\vv{u}}, q)} \setminus \diag(\collapse{\vv{u}}q)$ when $p > \beta$.  
\end{lemma}


\begin{proof}[Sketch of proof]
Pick an integer $D$ relative to $A$ as in 
\Cref{uniform denominators for mc:  T}, and sets $\orep(A, \vv{u}, \vv{s},q)$ as in \Cref{orep: D}. 
Choose $p \gg 0$ such that $p/D$ overwhelms any entry of any point in any $\orep(A, \vv{u}, \vv{s},q)$, and for which $p/D$ is greater than any coordinate of any point in $A(\orep(A))$, where $\orep(A)$ is as in \Cref{finiteness of optimal reps: R}.
Moreover, pick $\vv{s} \in \mc(A,\vv{u})
$ with denominator $D$ such that 
\[
 \Delta(A, \vv{u}, q) = \collapse{A}[\vv{s}]_q - \im \ip(A, \vv{u}, q).
\]
Then $\vv{h} \in \orep(A, \vv{u}, \vv{s},q)$ such that 
\[
 \vv{z} = \collapse{A}[\vv{s}]_q - \collapse{A} \vv{h}.
\] 
Then
$\vv{s} q - [\vv{s}]_q + \vv{h} \geq \vv{0}$ since $q \gg 0$.  Note that $\vv{s} q - [\vv{s}]_q + \vv{h}$ has nonnegative integer coordinates, and has norm $\nu(\collapse{\ideala}, \collapse{\vv{u}}, q)$.  
Hence
\[
 x^{A(\vv{s} q - [\vv{s}]_q + \vv{h})} \in \ideala^{\nu(\collapse{\ideala}, \collapse{\vv{u}}, q)}.
\]
We claim that this monomial is not in $\diag(\vv{u}q)$, i.e., 
$A(\vv{s} q - [\vv{s}]_q + \vv{h}) < \vv{u} q$. 
Projecting the left-hand side to  $\rs(\mathcal{O})^\perp$, this becomes $\collapse{\vv{u}} q - \vv{z}$ by construction. 

If $\widetilde{(\bullet)}$ denotes projection onto $\rs(\mathcal{O})^\perp$, then we claim that 
\begin{equation} \label{projection-claim}
 \widetilde{A \vv{s}} q - \widetilde{A [\vv{s}]_q} + \widetilde{A \vv{h}} < \widetilde{\vv{u}} q.
\end{equation}
Our choice of $\vv{s}$ implies that $\vv{u} = A \vv{s} + \vv{w}$ for some $\vv{w} \in \RR_+ \rb(\mathcal{O})$. Since $D$ is a denominator for $\vv{s}$ and $\vv{u}$ has integer coordinates, $\vv{w}$ must also have denominator $D$. 
Note that \eqref{projection-claim} holds if and only if
\[
  \widetilde{A \vv{h}} - \widetilde{A [\vv{s}]_q} < \widetilde{\vv{w}} q
\]
so that it suffices to show that $  \widetilde{A \vv{h}}  < \widetilde{\vv{w}} q$. 
Since $\vv{h} \in \orep(A)$, $A\vv{h} \in A(\orep(A))$, so by our choice of $p$, $p/D$ is greater than every entry of $A \vv{h}$.  On the other hand, each coordinate of $\widetilde{\vv{w}}$ must be at least $1/D$, and $\widetilde{A \vv{h}}  < \widetilde{\vv{w}} q$.
\end{proof}

We could restate in terms of programs:
\begin{lemma}
There exists $\beta = \beta(A)$ such that for all $q > \beta$ and $\vv{z} \in \Delta(A, \vv{u}, q)$, there exists $\vv{k} \in \operatorname{feas} \Pi(A, \vv{u}, q)$ with $\norm{\vv{k}} = \ft{A}{\vv{u}} q - \delta(A, \vv{u}, q)$ for which $\collapse{A \vv{k}} = \collapse{\vv{u}} q - \vv{z}$. 
\end{lemma}

\emily[inline]{
If we have a path 
\[
 (A, \vv{u}) \to (B, \vv{z})
\]
we can build $\vv{k}$ with $A \vv{k} < \vv{u} p$ and $\collapse{A\vv{k}} < \collapse{\vv{u}} p - \vv{z}$ 
}


Notice that these statements are very similar to \Cref{uniform value: P}. 




% \begin{lemma}[Extended lifting lemma]
%  There exists $\beta = \beta(A)$ with the following property\textup:  If $p > \beta$ and 
%  \[
% (A, \vv{u}) = (A_0, \vv{u}_0) \to (A_1, \vv{u}_1) \to \cdots \to (A_e, \vv{u}_e)
%  \]
%  is a sequence of $p$-sprouts, then for every $1 \leq i \leq e$, there exists $\vv{k}_i \in \opt \Pi(A_{i-1}, \vv{u}_{i-1} p)$ 
%  %with $\norm{\vv{k}_i} = \nu(A_{i-1}, \vv{u}_{i-1}, p)$ 
%  for which $A_i \vv{k}_i = \collapse{\vv{u}_{i-1}} p - \vv{u}_i$, where the bar denotes the collapse along $\mf(A_{i-1}, \vv{u}_{i-1})$, such that the following holds\textup: 
%  \[
%   \vv{k}_1 p^{e-1} + \vv{k}_2 p^{e-2} + \cdots + \vv{k}_{e-1} p + \vv{k}_e \in \feas \Pi(A, \vv{u}p^e).
%  \]
% \end{lemma}


% \emily[inline]
% {
% 
% \textbf{Conjecture.} $\val \Pi(A, \vv{u} p^e)$ is the max of the above expression, over sequences of $p$-sprouts of length $e$. 
% 
% \vspace{.4cm}
% 
% \textbf{Conjecture.} $\val \Pi(A, \vv{u} p^e) = M_2 p^{e-1} + M_3 p^{e-2} + \cdots + M_{e-1}$, where $M_i = \max \{ \nu(B, \vv{z}, p) : (B, \vv{z} \in \graph_i(A, \vv{u}) \}$.  
% }





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\daniel[inline]{This Proposition eventually becomes ``iterated lifting lemma''.  Once that proof is written down, this can go away}

\begin{proposition}
Suppose $A$ is a $d \times n$ monomial matrix and $\vv{u} \in \ZZ^d_+$.  Given an infinite rooted path 
\[ (A_1, \vv{u}_1) \to \cdots \to (A_e, \vv{u}_e) \to \cdots \] in $\graph_r(A, \vv{u})$ 
that is eventually periodic, there exists an integer $\beta$ such that 
\[  \left( \frac{ \vv{s}_1 \cdot p - \vv{t}_1}{p} + \cdots + \frac{ \vv{s}_e \cdot p - \vv{t}_e}{p^e} \right) \cdot p^e \] 
is optimal for $\IP_p(A, \vv{u}p^e)$ for every $e \geq 1$ whenever $p \geq \beta$ and $p \equiv r \bmod D$.
\end{proposition}

\begin{proof}   Throughout this proof, $p$ will always be a prime integer congruent to $r$ modulo $D$.  As such, the point $\vv{s}_c \cdot p - \vv{t}_c$  has nonnegative integer coordinates for every $e \geq 1$, and the eventual periodicity of the realization sequence implies that $\vv{s}_c \cdot p - \vv{t}_c$ has nonnegative integer coordinates for all $p \gg 0$ and $e \geq 1$.   Furthermore, the fact that $\vv{s}_c$ is a minimal coordinate for $(A_c, \vv{u}_c)$ tells us that the norm of $\vv{s}_c \cdot p - \vv{t}_c$ is $\ft{A_c}{\vv{u}_c} \cdot p - \norm{\vv{t}_c}$.  However, by definition of the graph $\graph_r(A, \vv{u})$, we know that the $\ft{A_c}{\vv{u}_c} \leq 1$ and that $\norm{\vv{t}_c} > 0$, and so the point above has norm less than $p$.  In summary, we have just seen that the point
\[  \left( \frac{ \vv{s}_1 \cdot p - \vv{t}_1}{p} + \cdots + \frac{ \vv{s}_e \cdot p - \vv{t}_e}{p^e} \right) \cdot p^e \] satisfies the arithmetic constraint of $\IP_p(A, \vv{u}p^e)$ for every $p \gg 0$ and $e \geq 1$.  

Therefore, to complete the proof, it suffices to show that 
\begin{equation}
\label{goal: e}
A   \left( \frac{ \vv{s}_1 \cdot p - \vv{t}_1}{p} + \cdots + \frac{ \vv{s}_e \cdot p - \vv{t}_e}{p^e} \right) < \vv{u} 
\end{equation}
for all $p \gg 0$ and $e \geq 1$.  We begin by considering the simple case that $\mf(A_e, \vv{u}_e)$ is bounded for every $e \geq 1$.  In this case, $A = A_e$ and $\vv{u}_e$ is positive in $\RR^d$ for all $e$.  Furthermore, $A \vv{s}_1 = \vv{u}$ while \[ A \vv{t}_c = \vv{u}_{c+1} = A \vv{s}_{c+1} \] for every $c \geq 1$.   Given this, a direct computation will show that 
\[ A   \left( \frac{ \vv{s}_1 \cdot p - \vv{t}_1}{p} + \cdots + \frac{ \vv{s}_e \cdot p - \vv{t}_e}{p^e} \right)  = A \vv{s}_1 - \frac{A \vv{t}_e}{p^e} = \vv{u} - \frac{\vv{u}_{e+1}}{p^e} \] which is less than $\vv{u}$ since $\vv{u}_{e+1}$ is positive.  



We will next establish \eqref{goal: e} in general by inducing on $d$, the number of rows of $A$.    If $d=1$, then the only proper face of the Newton polyhedron associated to $A$ is bounded, and so we are in the case considered above.    

Next, assume that $d>1$ and that \eqref{goal: e} has been proved for all $c \times n$ monomial matrices with $1 \leq c < d$.    By our earlier work, we may assume that $\mf(A_c, \vv{u}_c)$ is unbounded for some $c \geq 1$.  Let $l \geq 1$ be the minimum integer such that $\mf(A_l, \vv{u}_l)$ is unbounded.  If $l=1$, then obviously $A_l = A$. Otherwise, the minimality of $l$ implies that $\mf(A_c, \vv{u}_c)$ is bounded for all $1 \leq c < l$, which would then imply that $A_c = A$ for all $1 \leq c \leq l$.  Thus, setting $(B, \vv{v}) = (A_{l+1}, \vv{u}_{l+1})$, the path under consideration is of the form \[ (A, \vv{u}_1) \to \cdots \to (A, \vv{u}_l) \to (B, \vv{v}) \to \cdots. \]

 Set  $\O = \mf(A, \vv{u}_l)$, which is an unbounded face of the Newton polyhedron of $A$.  The unboundedness of $\O$ implies that $B$  is a monomial matrix with fewer than $d$ rows.  Moreover, the tail sequence 
\[ (\vv{s}_{l+1}, \vv{t}_{l+1}) \to \cdots \to (\vv{s}_{l+e}, \vv{t}_{l+e}) \to \cdots \] is a realization of the path \[ (B, \vv{v}) \to \cdots \to (A_{l+e}, \vv{u}_{l+e}) \to \cdots \] in the graph $\graph_r(B, \vv{v})$.  For every $e \geq 1$ set \[ \vv{k}_e = \frac{ \vv{s}_{l+1} \cdot p - \vv{t}_{l+1}}{p} + \cdots + \frac{ \vv{s}_{l+e} \cdot p - \vv{t}_{l+e}}{p^e}.  \]   By our induction hypothesis, we know that $B \vv{k}_e < \vv{v}$ for all $p \gg 0$ and $e \geq 1$.

Next, set \[ \vv{h} = \frac{\vv{s}_1 \cdot p - \vv{t}_1}{p} + \cdots + \frac{ \vv{s}_l \cdot p - \vv{t}_l}{p^l}. \] 
As $\vv{s}_l$ is a minimal coordinate for $(A, \vv{u}_l)$, we may write 
%
\begin{equation}
 \label{l-th term: e}
 \vv{u}_l = A \vv{s}_l + \vv{w}
 \end{equation}
 %
 for some $\vv{w} \in \QQ_+ \rb(\O)$, and we claim that   
\begin{equation} 
\label{A telescoping: e}
A \vv{h} = A \vv{s}_1 - \left( \frac{\vv{w}}{p^{l-1}} + \frac{A \vv{t}_l}{p^l} \right).  
\end{equation}  
The assertion is trivial if $l =1$.  If $l > 1$, then the face $\mf(A, \vv{u})$ is bounded, and so $A \vv{s}_1 = \vv{u}$.  In fact,  the face $(A, \vv{u}_c)$ is also bounded for every $1 \leq c < l$, which implies that $A \vv{t}_c = \vv{u}_{c+1} = A \vv{s}_{c+1}$ for every such $c$.  On the other hand, \eqref{l-th term: e} tells us that $A \vv{s}_l = \vv{u}_l - \vv{w}$.  A direct computation of the telescoping sum $A \vv{h}$ will then produce the identity recorded above.  

To conclude the proof, it remains to show that 
%
\begin{equation} 
\label{ineq to end proof: e}
A \left( \vv{h} + \frac{\vv{k}_e}{p^l} \right) < \vv{u}. 
\end{equation}
%
for all $p \gg 0$ and $e \geq 1$.

We begin by verifying \eqref{ineq to end proof: e} in $\rs(\O)^{\perp}$.  Let $\collapse{X}$ denote the image of a subset $X$ of $\RR^d$ under the projection $\RR^d \to \rs(\O)^{\perp}$, so that $\collapse{A \vv{t}} = B \vv{t}$ for every $\vv{t} \in \RR^n$.    By construction, $\vv{s}_1$ is a minimal coordinate of $(A, \vv{u})$.  If $l > 1$, then $A \vv{s}_1 = \vv{u}$, and if $l =1$, then $A \vv{s}_1$ differs from $\vv{u}$ by an element of $\rs(\O)$.  In any case, $B \vv{s}_1 = \collapse{\vv{u}}$.   The assumption that there is an edge  between $(A, \vv{u}_l)$ and $(B, \vv{v})$ in $\graph_r(A, \vv{u})$ also tells us that $B \vv{t}_l = \vv{v}$, and combining these observations with \eqref{A telescoping: e} shows that
$B \vv{h} = \collapse{A \vv{h}}$ equals $\collapse{\vv{u}} - p^{-l} \cdot \vv{v}$.  Thus, 
\[  B \left( \vv{h} + \frac{\vv{k}_e}{p^l} \right) = \collapse{\vv{u}} -  \frac{\vv{v} - B \vv{k}_e}{p^l}. \]
However, as noted above, our induction hypothesis tells us that the difference  $\vv{v} - B \vv{k}_e$ is positive in $\rs(\O)^{\perp}$ for every $p \gg 0$ and $e \geq 1$.    

We now turn our attention to verifying \eqref{ineq to end proof: e} in $\rs(\O)$.   Rewrite
\[ \frac{\vv{k}_e}{p^l} = \frac{\vv{s}_{l+1}}{p^{l+1}}- \left ( \sum_{i=1}^{e-1} \frac{ \vv{t}_{l+i} - \vv{s}_{l+i+1}}{p^{l+i}}  + \frac{ \vv{t}_{l+e}}{p^{l+e}} \right) \] as a polynomial in $p^{-1}$.  If we define the sequences $\{ \vv{c}_i \}_{i=1}^{\infty}$ and $\{ \vv{d}_i \}_{i=1}^{\infty}$ in $\RR^d$ according to the rule $\vv{c}_i = A ( \vv{t}_i - \vv{s}_{i+1})$ and $\vv{d}_i = A \vv{t}_i$, then the eventual periodicity of the realization path 
\[ (\vv{s}_{l+1}, \vv{t}_{l+1}) \to \cdots \to (\vv{s}_{l+e}, \vv{t}_{l+e}) \to \cdots \] implies that $\vv{c}_i$ and $\vv{d}_i$ take on only finitely many values as $i$ varies.    Moreover, the above polynomial expression in $p^{-1}$ and \eqref{A telescoping: e} tell us that 
%
\[ A \left( \vv{h} + \frac{\vv{k}_e}{p^l} \right)  =  A \vv{s}_1 - \left( \frac{\vv{w}}{p^{l-1}} + \frac{ \vv{c}_{l}}{p^{l}} + \cdots +  \frac{ \vv{c}_{l+e-1}}{p^{l+e-1}} + \frac{\vv{d}_{l+e}}{p^{l+e}} \right).  \] 
%
As $\vv{s}_1$ is a minimal coordinate for $\vv{u}$, we have that $A \vv{s}_1 \leq \vv{u}$, and so to conclude the proof, it suffices to show that quantity being subtracted above is positive in $\rs(\O)$ for all $p \gg 0$ and $e \geq 1$.  Equivalently, multiplying this expression by $p^{l+e}$, we have reduced to showing that 
\[ \vv{w} \cdot p^{e+1} + \vv{c}_l \cdot p^{e} + \cdots + \vv{c}_{l+e-1} \cdot p + \vv{d}_{l+e} \] is positive in $\rs(\O)$ for all $p \gg 0$ and $e \geq 1$.  However, $\vv{w}$ is positive in $\rs(\O)$ and the sequences $\{ \vv{c}_i \}$ and $\{ \vv{d}_i \}$ obtain only finitely many values, and so \Cref{positive polynomial: L} below allows us to conclude our proof.

\end{proof}



% \section{The main players (repeated later on)}
% 
% \begin{definition}
% A \emph{monomial matrix} is a matrix over $\ZZ$ with nonnegative, nonzero rows and columns.   If $A$ is a $d \times n$ monomial matrix, then we call $\ZZ^n$ the \emph{domain lattice}, and $\ZZ^d$ the \emph{range lattice}, of $A$.
% \end{definition}
% 
% \begin{definition}
% A \emph{monomial pair} $(A, \vv{u})$ consists of a monomial matrix $A$ and a positive point $\vv{u}$ in the range lattice of $A$.
% \end{definition}
% 
% 
% \comment[inline]{In what follows, $(A, \vv{u})$ is a $d \times n$ monomial pair.
%  Think about $A$ as the matrix whose columns correspond to the generators of a monomial ideal $\ideala$, and let $\ideald$ be the diagonal ideal determined by $\vv{u}$. }
% 
% 
% \begin{definition}
% $\LP(A, \vv{u})$ is the linear program defined as follows:
% \begin{enumerate}
% \item The constraints are $\vv{k} \geq \vv{0}$ and $A \vv{k} \leq \vv{u}$.
% \item The objective function is $\vv{k} \mapsto \norm{\vv{k}}$.
% \end{enumerate}
% \end{definition}
% 
% \comment[inline]{$ \val \LP(A, \vv{u}) = \ft{\ideala}{\ideald}$, as recorded in \Cref{FT descriptions: P}.}
% 
% 
% \begin{definition}
% $\IP(A, \vv{u})$ is the integer program in $\ZZ^n$ defined as follows:
% \begin{enumerate}
% \item The constraints are $\vv{k} \geq \vv{0}$ and $A \vv{k} < \vv{u}$. 
% \item The objective function is $\vv{k} \mapsto \norm{\vv{k}}$.
% \end{enumerate}
% \end{definition}
% 
% \comment[inline]{$\val \IP(A, \vv{u} q) = \nu_{\ideala}^{\ideald}(q)$ for every $q = p^e$.}
% 
% 
% \begin{definition} If $p>0$ is a prime integer, then $\IP_p(A, \vv{u})$ is the arithmetic integer program in $\ZZ^n$ defined as follows:
% \begin{enumerate}
% \item The linear constraints are $\vv{k} \geq \vv{0}$ and $A \vv{k} < \vv{u}$.  
% \item The nonlinear (arithmetic) constraint is that $\binom{\norm{\vv{k}}}{\vv{k}} \not \equiv 0 \bmod p$.  By Lucas' Theorem, this is equivalent to the condition that  if \[ \vv{k} = \vv{k}_0 + \cdots + \vv{k}_l \cdot  p^l\] is the unique base $p$ expansion of $\vv{k}$, then $\norm{\vv{k}_s} < p$ for all $0 \leq s \leq l $.
% \item The objective function is $\vv{k} \mapsto \norm{\vv{k}}$.
% \end{enumerate}
% \end{definition}
% 
% \comment[inline]{$\val \IP_p(A, \vv{u} q) = \mu_{\ideala}^{\ideald}(q)$ for every $q = p^e$.}









